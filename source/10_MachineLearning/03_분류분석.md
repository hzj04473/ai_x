# 📔 03_분류분석.ipynb 코드 해설 (상세 최종본)

안녕하세요! 이 문서는 `03_분류분석.ipynb` 노트북 파일의 전체 내용을 처음 머신러닝을 접하는 분들도 쉽게 이해할 수 있도록 상세한 설명과 참고 자료를 더해 새롭게 구성한 최종 해설 문서입니다.

---

## 1. 분류 분석 (Classification) 이란?

분류 분석은 머신러닝의 대표적인 **지도 학습(Supervised Learning)** 방법 중 하나입니다. 지도 학습이란, '정답'이 있는 데이터(Feature)를 사용해 모델을 학습시킨 뒤, 새로운 데이터가 어떤 카테고리(클래스)에 속하는지 예측하는 문제를 말합니다.

-   **예시:** 스팸 메일 분류, 고객 등급 예측(VIP, 일반), 질병 진단(양성, 음성) 등
-   **핵심:** 입력 데이터(X)를 보고 정답(y, 클래스)을 맞추는 모델을 만드는 것

> 🔗 **참고 자료:**
>
> -   [지도 학습이란? (위키백과)](https://ko.wikipedia.org/wiki/%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5)
> -   [Scikit-Learn 공식 홈페이지 (영문)](https://scikit-learn.org/stable/)

---

## 2. 데이터 불러오기: MNIST 손글씨 숫자

MNIST는 손으로 쓴 0부터 9까지의 숫자 이미지 데이터셋으로, 분류 모델을 학습하고 테스트하는 데 가장 널리 사용되는 표준 데이터셋입니다.

### 방법 1: `tensorflow.keras` 사용

```python
from tensorflow.keras.datasets import mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()
```

-   딥러닝 라이브러리인 TensorFlow(Keras)를 통해 데이터를 불러옵니다.
-   데이터는 `(60000, 28, 28)` 형태로, 28x28 픽셀 크기의 이미지 6만 장으로 구성됩니다.

### 방법 2: `sklearn.datasets.fetch_openml` 사용

```python
from sklearn.datasets import fetch_openml
mnist = fetch_openml(name="mnist_784", version=1, as_frame=False, parser="auto")
X, y = mnist.get("data"), mnist.get("target").astype(int)
```

-   Scikit-learn을 통해 인터넷에서 데이터를 다운로드합니다.
-   데이터는 `(70000, 784)` 형태로, 28x28 이미지가 784개의 1차원 배열로 펼쳐져(flatten) 있습니다.
-   `X.reshape(-1, 28, 28)` 코드를 통해 다시 28x28 이미지 형태로 복원하여 시각화할 수 있습니다.

---

## 3. 분류 모델의 종류

분류 모델은 크게 두 가지 접근 방식으로 나눌 수 있습니다.

1.  **확률적 모형**: 각 클래스일 확률(e.g., "이 이미지는 70% 확률로 '고양이', 30% 확률로 '개'")을 계산합니다.
    -   **생성 모형 (Generative)**: 각 클래스별 데이터 분포를 학습합니다. (e.g., QDA, 나이브 베이즈)
    -   **판별 모형 (Discriminative)**: 클래스 간의 경계선을 학습합니다. (e.g., 로지스틱 회귀, 의사결정나무)

2.  **판별 함수 모형**: 확률 계산 없이 클래스를 나누는 경계면(결정 경계)을 직접 찾습니다. (e.g., 서포트 벡터 머신, 신경망)

---

## 4. 모델 실습: 확률적 모형

### 4-1. QDA (Quadratic Discriminant Analysis)

QDA는 각 클래스의 데이터가 특정 정규분포를 따른다고 가정하는 **확률적 생성 모델**입니다.

-   **가상 데이터 생성 (`make_classification`)**: `scikit-learn`으로 QDA를 테스트하기 위한 가상의 2차원 데이터를 100개 생성합니다.
-   **모델 학습 및 예측**:
    ```python
    from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
    model = QuadraticDiscriminantAnalysis().fit(X, y)
    model.predict([[5, 5]]) # 예측
    model.predict_proba([[5, 5]]) # 확률 계산
    ```

### 4-2. 나이브 베이즈 (Naive Bayes)

각 특성(feature)이 서로 독립적이라고 '순진하게(naively)' 가정하고 베이즈 정리를 사용하는 **확률적 생성 모델**입니다.

-   **데이터 및 모델**: `seaborn`의 붓꽃(iris) 데이터와 `MultinomialNB` 모델을 사용합니다.
-   **특징**: `y`값이 문자열(`'setosa'`)이어도 별도의 변환(Label Encoding) 없이 학습이 가능합니다.
-   `predict_log_proba()`: 확률 값이 매우 작을 때 값의 차이를 더 명확하게 비교하기 위해 로그를 취한 값을 반환합니다.

### 4-3. 로지스틱 회귀 (Logistic Regression)

이름에 '회귀'가 들어가지만 실제로는 **분류 모델**입니다. S자 형태의 **시그모이드(Sigmoid) 함수**를 사용해 결과를 0과 1 사이의 확률 값으로 만듭니다.

-   **시각화**: `model.predict_proba()`로 계산된 확률을 그래프로 그리면 S자 형태의 시그모이드 곡선이 나타나는 것을 확인할 수 있습니다.

### 4-4. 의사결정나무 (Decision Tree)

데이터를 특정 기준으로 나누는 과정을 반복하여 분류하는 모델입니다. **어떤 독립변수가 종속변수에 영향을 주는지 파악**하는 데 유용합니다.

-   **주요 파라미터**:
    -   `criterion='entropy'`: 정보 이득을 기준으로 데이터를 분할합니다.
    -   `max_depth`: 트리의 최대 깊이를 제한하여 과적합을 방지합니다.
-   **시각화**: `export_graphviz`를 사용해 트리의 구조를 시각적으로 확인할 수 있어 해석이 용이합니다.

---

## 5. 모델 실습: 판별 함수 모형

확률을 직접 계산하는 대신, 데이터를 가장 잘 나누는 **경계선(결정 경계)을 찾는 데 집중**하는 모델입니다. `predict_proba()` 대신 `decision_function()`을 주로 사용합니다.

### 5-1. 서포트 벡터 머신 (SVM, Support Vector Machine)

각 클래스의 데이터와 **가장 멀리 떨어진 경계선(Margin을 최대화하는 선)**을 찾아 분류하는 모델입니다.

-   `decision_function()`: 결정 경계로부터 각 데이터가 얼마나 떨어져 있는지 거리를 반환합니다.

### 5-2. 퍼셉트론 (Perceptron)

인공신경망의 가장 기본적인 형태로, 여러 입력을 받아 하나의 출력을 내보냅니다.

-   `max_iter`: 학습 반복 횟수 (epoch)
-   `eta0`: 학습률 (learning rate)

### 5-3. 다중 퍼셉트론 (MLP, Multi-Layer Perceptron)

여러 개의 퍼셉트론 층으로 이루어진 **인공신경망**입니다. 더 복잡한 비선형 문제도 해결할 수 있습니다.

-   `hidden_layer_sizes`: 은닉층의 구조와 뉴런 수를 지정합니다. `(50, 50, 30)`은 3개의 은닉층에 각각 50, 50, 30개의 뉴런이 있음을 의미합니다.
-   `activation`: 활성화 함수를 지정합니다. (e.g., `relu`)
-   **특징**: `predict_proba()`와 `decision_function()`을 모두 사용할 수 있습니다.

---

## 6. 분류 모델 성능 평가

모델이 얼마나 정확하게 예측하는지 측정하는 과정은 매우 중요합니다.

### 6-1. 혼동 행렬 (Confusion Matrix)

실제 값과 예측 값을 표로 나타내어 모델의 성능을 한눈에 파악할 수 있습니다.

| | 예측: Positive | 예측: Negative |
| :--- | :---: | :---: |
| **실제: Positive** | TP | FN |
| **실제: Negative** | FP | TN |

-   **TP (True Positive)**: 실제 Positive를 Positive로 맞게 예측
-   **TN (True Negative)**: 실제 Negative를 Negative로 맞게 예측
-   **FP (False Positive)**: 실제 Negative를 Positive로 잘못 예측 (Type 1 Error)
-   **FN (False Negative)**: 실제 Positive를 Negative로 잘못 예측 (Type 2 Error)

### 6-2. 주요 성능 지표

-   **정확도 (Accuracy)**: `accuracy_score`
    -   전체 예측 중 올바르게 예측한 비율. `(TP+TN) / (TP+TN+FP+FN)`
    -   가장 직관적이지만, 데이터가 불균형할 경우(e.g., 사기 예측) 성능을 왜곡할 수 있습니다.

-   **정밀도 (Precision)**: `precision_score`
    -   Positive로 예측한 것 중 실제 Positive인 비율. `TP / (TP+FP)`
    -   *e.g., 스팸 메일 분류에서 중요 (일반 메일을 스팸으로 잘못 분류하면 안 됨)*

-   **재현율 (Recall)**: `recall_score`
    -   실제 Positive인 것 중 Positive로 예측한 비율. `TP / (TP+FN)`
    -   *e.g., 암 진단 모델에서 중요 (실제 암 환자를 놓치면 안 됨)*

-   **F1 Score**: `f1_score`
    -   정밀도와 재현율의 조화 평균. `(2 * Precision * Recall) / (Precision + Recall)`
    -   두 지표가 모두 중요할 때 사용합니다.

### 6-3. ROC Curve 와 AUC

정확도, 정밀도, 재현율은 분류의 기준이 되는 **임계값(Threshold)**이 고정되었을 때의 성능입니다. 하지만 모델이 예측하는 확률 값을 기준으로, 이 임계값을 계속 변경하면서 모델의 성능을 종합적으로 평가하는 방법이 바로 ROC Curve입니다.

-   **FPR (False Positive Rate, 위양성율)**: 실제 Negative 중 Positive로 잘못 예측한 비율. `FP / (FP + TN)`
-   **TPR (True Positive Rate, 진양성율)**: 실제 Positive 중 Positive로 맞게 예측한 비율. (재현율과 동일) `TP / (TP + FN)`

**ROC (Receiver Operating Characteristic) Curve**는 분류 모델의 임계값이 변할 때 FPR과 TPR이 어떻게 변하는지를 나타내는 그래프입니다.

-   **x축**: FPR (1 - 특이도)
-   **y축**: TPR (민감도, 재현율)

그래프가 **왼쪽 위 모서리(좌상단)에 가까울수록** FPR은 낮게 유지하면서 TPR은 높은 좋은 모델임을 의미합니다.

**AUC (Area Under the Curve)**는 ROC Curve 그래프 아래의 면적을 의미합니다.

-   **1에 가까울수록** 모델의 성능이 좋음을 나타냅니다. (완벽한 모델은 AUC=1)
-   **0.5에 가까울수록** 모델이 무작위로 예측하는 것과 비슷한 수준임을 의미합니다. (AUC=0.5는 성능이 없음)
-   AUC는 임계값에 관계없이 모델의 전반적인 성능을 나타내므로, **데이터가 불균형할 때도 모델을 객관적으로 비교**하기 좋은 지표입니다.

#### 코드 해설

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# 모델이 예측한 Positive(클래스 1)일 확률
# decision_function()을 사용하거나 predict_proba()[:, 1]을 사용
y_score = model.decision_function(X_test) 

# roc_curve 함수로 fpr, tpr, thresholds 계산
fpr, tpr, thresholds = roc_curve(y_test, y_score)

# AUC 스코어 계산
auc = roc_auc_score(y_test, y_score)

# ROC Curve 시각화
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier') # 기준선
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
```
- `roc_curve(y_true, y_score)`: 실제값과 모델이 예측한 확률(또는 점수)을 입력받아 FPR, TPR, 그리고 그 때의 임계값들을 반환합니다.
- `roc_auc_score(y_true, y_score)`: 실제값과 예측 확률을 받아 AUC 점수를 직접 계산해줍니다.
- 시각화 코드에서는 계산된 `fpr`과 `tpr`을 x, y축으로 하여 그래프를 그리고, AUC 점수를 범례에 표시하여 모델의 성능을 직관적으로 보여줍니다.

---

오늘 수업에서는 다양한 분류 모델의 기본 개념과 `scikit-learn`을 이용한 실습, 그리고 모델의 성능을 상세하게 평가하는 방법까지 배웠습니다. 각 모델과 평가지표의 특징을 잘 이해하고 상황에 맞게 사용하는 것이 중요합니다.
