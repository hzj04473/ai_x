# 실전 데이터 분석 2: 심장병 발병 예측 및 모델 성능의 깊은 이해

피마 인디언 당뇨병 예측에 이어, 이번에는 `07_심장병발병예측(이진,분류).ipynb` 노트북을 통해 또 다른 실제 의료 데이터셋으로 심장병 발병 여부를 예측해 보겠습니다. 이 노트북은 단순히 모델을 만드는 것을 넘어, **현실의 데이터가 얼마나 지저분할 수 있는지(messy data)**, 그리고 이를 어떻게 다루고 모델의 성능을 **과적합(Overfitting)** 없이 안정적으로 향상시키는지에 대한 중요한 기법들을 소개합니다.

## 1. 데이터셋과 전처리: 현실 세계의 데이터 다루기

- **데이터**: `heart-disease.xlsx` 파일은 환자들의 나이, 성별, 콜레스테롤 수치 등 13개의 의료 관련 특성(Feature)과 심장병 발병 여부(Target)를 담고 있습니다.

### 1.1. 전처리 과정: 데이터 클리닝 및 정제

현실의 데이터는 결측치나 오류가 포함된 경우가 많습니다. 이 노트북의 전처리 과정은 매우 현실적이고 중요합니다.

1.  **엑셀 파일 로드**: `pandas.read_excel`을 사용해 데이터를 불러옵니다.
2.  **결측치 식별**: 데이터에 숫자 대신 `'?'` 문자가 포함된 것을 확인합니다. 이는 숨겨진 결측치입니다.
3.  **결측치 변환**: `df.replace('?', np.nan)`을 사용해 `'?'`를 NumPy가 인식할 수 있는 결측치(`NaN`)로 변환합니다.
4.  **결측치 처리**: `df.fillna(value=df.median(), inplace=True)`를 사용해 각 열의 결측치를 해당 열의 **중앙값(median)**으로 대체합니다. 평균(mean) 대신 중앙값을 사용하는 이유는 이상치(outlier)의 영향을 덜 받기 때문입니다.
5.  **데이터 분리**: 독립 변수(X)와 종속 변수(y)를 분리합니다.
6.  **피처 스케일링**: `MinMaxScaler`를 사용해 모든 독립 변수의 값 범위를 0과 1 사이로 조정합니다. 이는 모델의 학습 성능과 안정성을 높이는 데 필수적입니다.
7.  **훈련/테스트 데이터 분할**: `train_test_split`을 사용해 데이터를 나눕니다.
    - **`stratify=y`**: 이 옵션은 매우 중요합니다. 훈련셋과 테스트셋의 타겟 변수(y) 비율이 원래 데이터셋의 비율과 동일하게 유지되도록 데이터를 분할합니다. 예를 들어, 원래 데이터에 정상:환자 비율이 6:4였다면, 훈련셋과 테스트셋도 모두 6:4 비율을 갖게 되어 모델이 편향되지 않게 학습하고 공정하게 평가받을 수 있습니다.

### 1.2. 과적합 방지를 위한 기법: Dropout

- **과적합(Overfitting)**: 모델이 훈련 데이터에만 너무 과하게 학습되어, 새로운 데이터(테스트 데이터)에 대해서는 성능이 오히려 떨어지는 현상입니다. 학습 그래프에서 `train_loss`는 계속 감소하는데 `val_loss`가 증가하기 시작하면 과적합을 의심할 수 있습니다.
- **드롭아웃(Dropout)**: 과적합을 방지하는 대표적인 규제(Regularization) 기법입니다. 학습 과정에서 각 층(Layer)의 일부 뉴런을 무작위로 비활성화(dropout)시킵니다. 이를 통해 모델이 특정 뉴런에만 너무 의존하는 것을 막고, 더 일반화된(robust) 패턴을 학습하도록 강제합니다.

```python
from tensorflow.keras.layers import Dropout

model.add(Dense(units=32, activation='relu'))
model.add(Dropout(0.3)) # 이 층의 뉴런 중 30%를 무작위로 비활성화
```

## 2. 모델링 및 평가

### 2.1. 이진 분류 모델

피마 인디언 예제와 유사하게, `sigmoid`를 출력층의 활성화 함수로, `binary_crossentropy`를 손실 함수로 사용하는 이진 분류 모델을 구축합니다. `Adam` 옵티마이저를 사용하고, `Recall`과 `Precision`을 평가지표에 추가하여 학습 과정을 상세히 모니터링합니다.

```python
model.compile(
    loss="binary_crossentropy",
    optimizer=Adam(learning_rate=0.01),
    metrics=[
        'binary_accuracy', 
        metrics.Recall(),    # 재현율
        metrics.Precision()  # 정밀도
    ])
```

학습 후, `evaluate`를 통해 테스트셋에서의 최종 성능을 확인하고, 혼동 행렬(Confusion Matrix)을 통해 모델이 어떤 종류의 오류를 범하고 있는지 상세하게 분석합니다.

### 2.2. 다중 분류 모델로 접근하기

이진 분류 문제를 다중 분류 문제로 변환하여 모델링하는 방법도 보여줍니다. 이는 `softmax` 함수의 작동 원리와 다중 분류 모델의 구조를 이해하는 데 도움을 줍니다.

- **데이터 변환**: `to_categorical`을 사용해 `y` 데이터를 원-핫 인코딩합니다. (0 -> `[1, 0]`, 1 -> `[0, 1]`)
- **모델 변경**:
    - 출력층: `Dense(units=2, activation='softmax')`로 변경합니다. 출력 뉴런이 2개가 되고, 두 출력의 합은 1이 되어 각 클래스에 속할 확률을 나타냅니다.
    - 손실 함수: `loss='categorical_crossentropy'`로 변경합니다.
- **예측**: `model.predict(X_test).argmax(axis=1)`를 사용해 두 클래스 중 더 높은 확률을 가진 클래스를 최종 예측값으로 선택합니다.

## 3. 핵심 요약

- **현실 데이터는 지저분하다**: `'?'`와 같은 문자열을 `NaN`으로 변환하고, 중앙값 등으로 대체하는 전처리 과정은 필수입니다.
- **`stratify` 옵션**: 분류 문제에서 데이터를 분할할 때 클래스 비율을 유지하는 것은 모델의 신뢰도를 위해 매우 중요합니다.
- **Dropout**: 딥러닝 모델의 과적합을 막는 간단하고 효과적인 방법입니다.
- **정확도 외의 평가지표**: 의료 진단 등에서는 재현율(Recall)과 정밀도(Precision)가 정확도보다 더 중요한 평가 기준이 될 수 있습니다.
- **이진 vs. 다중 분류**: 문제에 따라 출력층의 활성화 함수(`sigmoid` vs `softmax`)와 손실 함수(`binary_crossentropy` vs `categorical_crossentropy`)를 올바르게 선택해야 합니다.

이 노트북은 실제 데이터 분석 프로젝트의 축소판과 같습니다. 데이터 정제부터 모델링, 그리고 깊이 있는 평가까지의 전체 흐름을 잘 이해하는 것이 중요합니다.
