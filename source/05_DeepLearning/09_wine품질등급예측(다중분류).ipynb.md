# 다중 클래스 분류: 와인 품질 등급 예측

지금까지 이진 분류(0 또는 1)와 MNIST를 이용한 다중 분류(0~9)를 다루었습니다. 이번 `09_wine품질등급예측(다중분류).ipynb` 노트북에서는 레드 와인의 화학적 특성을 분석하여 품질 등급을 예측하는, 보다 현실적인 **다중 클래스 분류(Multi-class Classification)** 문제를 해결합니다.

특히 이 노트북에서는 모델의 학습을 더 효율적이고 지능적으로 제어하는 강력한 도구인 **콜백(Callbacks)**, 구체적으로 **조기 종료(Early Stopping)**와 **모델 체크포인트(Model Checkpoint)**에 대해 배웁니다.

## 1. 문제 정의 및 데이터 전처리

- **데이터셋**: `winequality-red.csv` 파일은 레드 와인의 고정 산도, pH, 알코올 도수 등 11개의 화학적 특성(독립 변수)과 3에서 8까지의 품질 등급(종속 변수)을 포함합니다.
- **목표**: 11개의 화학적 특성을 바탕으로 와인의 품질 등급(6개 클래스: 3, 4, 5, 6, 7, 8)을 예측하는 모델을 만듭니다.

### 1.1. 전처리 과정

1.  **데이터 로드 및 분리**: `pandas`로 CSV 파일을 읽고, 독립 변수(X)와 종속 변수(y)로 분리합니다.
2.  **피처 스케일링**: `StandardScaler`를 사용하여 모든 독립 변수를 표준화합니다. 이는 각 특성의 단위와 값의 범위가 다른 문제를 해결하고 모델 학습을 돕습니다.
3.  **타겟 변수 원-핫 인코딩**: 품질 등급은 3, 4, 5, 6, 7, 8의 순서가 있는 숫자로 보이지만, 실제로는 순서의 의미보다 각기 다른 '등급'이라는 범주형 데이터입니다. 따라서 `to_categorical`을 사용해 원-핫 인코딩으로 변환합니다. (예: 등급 5 -> `[0,0,0,0,0,1,0,0,0]`)
4.  **데이터 분할**: `train_test_split`을 사용해 훈련셋과 테스트셋으로 나눕니다. `stratify=y` 옵션을 사용하여 각 등급의 와인이 훈련셋과 테스트셋에 비슷한 비율로 분포되도록 합니다. 이는 데이터 불균형 문제(특정 등급의 와인이 매우 적음)를 완화하는 데 중요합니다.

## 2. 모델링과 똑똑한 학습 제어: Callbacks

`epochs`를 무작정 많이 설정하면 학습 시간이 길어지고 과적합이 발생할 수 있습니다. **콜백(Callbacks)**은 학습 과정의 특정 지점(예: 에포크 종료 시)에 원하는 동작을 수행하도록 하는 기능으로, 이러한 문제를 해결하는 데 도움을 줍니다.

### 2.1. 모델 구성

이전 예제들과 유사하게 여러 개의 `Dense` 층과 `Dropout` 층을 쌓아 딥러닝 모델을 구성합니다. 출력층은 9개의 뉴런(0~8등급)과 `softmax` 활성화 함수를 사용하여 각 품질 등급에 속할 확률을 계산합니다.

### 2.2. 핵심 콜백 함수

- **`EarlyStopping` (조기 종료)**: 모델의 성능이 더 이상 개선되지 않을 때 학습을 자동으로 중단시켜 과적합과 시간 낭비를 방지합니다.
    - `monitor='val_loss'`: 검증 손실(val_loss)을 모니터링합니다.
    - `patience=20`: 20번의 에포크 동안 `val_loss`가 개선되지 않으면 학습을 중단합니다.

- **`ModelCheckpoint` (모델 저장)**: 학습 과정 중 가장 성능이 좋은 모델을 파일로 저장합니다.
    - `filepath='./model/best_wine_model.h5'`: 모델을 저장할 경로와 파일명입니다.
    - `monitor='val_loss'`: 검증 손실을 기준으로 모델의 성능을 판단합니다.
    - `save_best_only=True`: `val_loss`가 이전보다 개선되었을 때만 모델을 덮어씁니다.

### 2.3. 모델 학습

```python
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

early_stopping = EarlyStopping(monitor='val_loss', patience=20)
model_checkpoint = ModelCheckpoint(filepath='./model/best_wine_model.h5', 
                                 monitor='val_loss', save_best_only=True)

hist = model.fit(X_train, y_train, epochs=1500, 
                 validation_data=(X_val, y_val),
                 callbacks=[early_stopping, model_checkpoint])
```
- `fit` 함수의 `callbacks` 인자에 준비된 콜백 객체들을 리스트 형태로 전달합니다.
- 이렇게 하면, 모델은 최대 1500번 학습하지만, 20번 동안 검증 손실이 개선되지 않으면 자동으로 멈추고, 그 과정에서 가장 검증 손실이 낮았던 시점의 모델이 `best_wine_model.h5` 파일로 저장됩니다.

## 3. 평가 및 결과 분석

학습이 완료된 후, 학습 과정 그래프와 `evaluate` 함수, 그리고 혼동 행렬을 통해 모델의 성능을 종합적으로 평가합니다. 특히 혼동 행렬을 통해 모델이 어떤 등급을 다른 등급으로 잘못 예측하는 경향이 있는지 파악할 수 있습니다. 와인 품질 데이터는 5, 6등급에 데이터가 집중되어 있어, 소수 클래스(3, 8등급)를 정확히 예측하는 것이 더 어려운 과제임을 확인할 수 있습니다.

## 4. 핵심 요약

- **다중 클래스 분류**: 여러 개의 범주 중 하나를 예측하는 문제로, 출력층의 활성화 함수로 `softmax`를, 손실 함수로 `categorical_crossentropy`를 사용하는 것이 표준적입니다.
- **데이터 불균형과 `stratify`**: 각 클래스의 데이터 개수가 차이 나는 불균형 데이터에서는 `train_test_split`의 `stratify` 옵션을 사용하여 데이터 분할 시 클래스 비율을 유지하는 것이 중요합니다.
- **`EarlyStopping`과 `ModelCheckpoint`**: 딥러닝 모델 학습 시 시간 낭비와 과적합을 방지하고, 최적의 모델을 자동으로 저장해주는 매우 유용하고 필수적인 도구입니다.

이 노트북은 실제 데이터를 다루는 전처리 과정부터, 과적합을 제어하며 효율적으로 모델을 학습시키는 고급 기법까지 다루는 종합적인 예제입니다.
