# 딥러닝 입문: 분류 (Classification) 모델 만들기

안녕하세요! 선형 회귀에 이어 이번에는 딥러닝의 또 다른 핵심 과제인 **분류(Classification)**에 대해 알아보겠습니다. 이 문서는 `02_딥러닝입문.ipynb` 파일의 코드를 바탕으로, 딥러닝을 이용해 데이터를 여러 그룹으로 나누는 방법을 설명합니다.

## 1. 회귀 vs. 분류: 무엇이 다른가요?

- **회귀(Regression)**: 연속적인 숫자 값을 예측합니다. (예: 온도를 예측, 집값 예측)
- **분류(Classification)**: 데이터가 어떤 카테고리(클래스)에 속하는지 예측합니다. (예: 이메일이 스팸인지 아닌지, 이미지가 고양이인지 강아지인지)

이 노트북에서는 입력된 숫자가 어떤 규칙에 따라 특정 카테고리로 분류되는지를 딥러닝 모델이 학습하도록 할 것입니다.

## 2. 딥러닝 모델링 과정 (지도학습 기준)

분류 모델을 만드는 과정은 회귀 모델과 매우 유사하지만, 몇 가지 중요한 차이점이 있습니다. 전체적인 흐름은 다음과 같습니다.

1.  **데이터 셋 준비**: 입력(X)과 정답(Y) 데이터를 준비합니다.
2.  **데이터 전처리**: 모델이 학습하기 좋은 형태로 데이터를 가공합니다. 특히 분류 문제에서는 **원-핫 인코딩(One-Hot Encoding)**이 핵심입니다.
3.  **모델 구성**: 여러 개의 층(Layer)을 쌓아 딥러닝 모델의 구조를 만듭니다.
4.  **모델 학습과정 설정**: 손실 함수, 옵티마이저, 평가지표를 설정하여 모델을 컴파일합니다.
5.  **모델 학습**: `fit` 함수로 모델을 훈련시킵니다.
6.  **모델 평가**: `evaluate` 함수와 그래프를 통해 모델의 성능을 확인합니다.
7.  **모델 사용**: `predict` 함수로 새로운 데이터의 클래스를 예측합니다.
8.  **모델 저장/로드**: 학습된 모델을 저장하고 다시 불러와 사용합니다.

## 3. 코드 해설: 단계별로 따라가기

### 3.1. 데이터 준비 및 전처리

**1. 데이터 생성 및 분할**

```python
import numpy as np

# 훈련, 검증, 테스트 데이터 생성
x_train = np.array([1,2,3,4,5,6,7,8,9]*10) # 훈련용 입력
y_train = np.array([2,4,6,8,10,12,14,16,18]*10) # 훈련용 정답

x_val = np.array([1,2,3,4,5,6,7,8,9]) # 검증용 입력
y_val = np.array([2,4,6,8,10,12,14,16,18]) # 검증용 정답

x_test = np.array([1,2,3,4,5,6,7,8,9]) # 테스트용 입력
y_test = np.array([2,4,6,8,10,12,14,16,18]) # 테스트용 정답
```
- **훈련(Train) 데이터**: 모델을 학습시키는 데 사용되는 대부분의 데이터입니다.
- **검증(Validation) 데이터**: 학습 중간중간 모델의 성능을 평가하여, 학습이 올바른 방향으로 가고 있는지 확인하는 데 사용됩니다. (예: 과적합 방지)
- **테스트(Test) 데이터**: 학습이 모두 끝난 후, 모델의 최종 성능을 평가하는 데 사용되는 데이터입니다. 이 데이터는 학습 과정에 전혀 관여하지 않아야 합니다.

**2. 핵심 전처리: 원-핫 인코딩 (One-Hot Encoding)**

컴퓨터는 'a', 'b', '서울', '부산' 같은 문자 데이터를 직접 이해하지 못합니다. 따라서 이를 숫자로 바꿔주는 과정이 필요합니다.

- **레이블 인코딩 (Label Encoding)**: 각 문자에 고유한 숫자를 부여합니다. (예: a=0, b=1, c=2)

```python
from sklearn.preprocessing import LabelEncoder

data = np.array(['a','b','c','d'])
le = LabelEncoder()
labeled_data = le.fit_transform(data)
# 결과: [0 1 2 3]
```

- **문제점**: 레이블 인코딩은 모델에게 카테고리 간의 순서나 크기 관계가 있다는 잘못된 정보를 줄 수 있습니다. (예: '부산'(1)이 '서울'(2)보다 작다고 오해)

- **원-핫 인코딩 (One-Hot Encoding)**: 이 문제를 해결하기 위해 사용됩니다. 각 카테고리를 0과 1로만 이루어진 벡터로 표현합니다. 해당되는 카테고리만 1이고 나머지는 모두 0입니다.

```python
from tensorflow.keras.utils import to_categorical

# 레이블 인코딩된 데이터를 원-핫 인코딩으로 변환
one_hot_encoded = to_categorical(labeled_data)
# 결과:
# [[1. 0. 0. 0.]  <- a
#  [0. 1. 0. 0.]  <- b
#  [0. 0. 1. 0.]  <- c
#  [0. 0. 0. 1.]] <- d
```

이 노트북에서는 정답 데이터(`y_train`, `y_val`, `y_test`)를 `to_categorical` 함수를 이용해 원-핫 인코딩으로 변환합니다.

```python
# 분류분석을 위한 target변수 라벨링 전환(원핫인코딩)
Y_train = to_categorical(y_train, 19)
Y_val = to_categorical(y_val, 19)
Y_test = to_categorical(y_test, 19)
```
- `num_classes=19`는 총 클래스의 개수를 19개로 지정하는 옵션입니다. (0부터 18까지)

### 3.2. 딥러닝 모델 만들기

**1. 모델 구조 정의**

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input

model = Sequential()
model.add(Input(shape=(1,))) # 입력층
model.add(Dense(units=38, activation='sigmoid')) # 은닉층 1
model.add(Dense(units=64, activation='elu'))     # 은닉층 2
model.add(Dense(units=32, activation='elu'))     # 은닉층 3
model.add(Dense(units=19, activation='softmax')) # 출력층
```
- **은닉층(Hidden Layer)**: 입력층과 출력층 사이에 있는 층들로, 더 복잡하고 깊은 패턴을 학습할 수 있게 해줍니다. 층을 여러 개 쌓았기 때문에 '딥(Deep)' 러닝이라고 부릅니다.
- **활성화 함수(Activation Function)**: 모델에 비선형성(non-linearity)을 추가하여 더 복잡한 문제를 풀 수 있게 해줍니다. 직선만으로는 표현할 수 없는 복잡한 관계를 학습하는 데 필수적입니다.
    - `sigmoid`, `elu`, `relu`, `tanh` 등 다양한 종류가 있습니다.
- **출력층(Output Layer)**:
    - `units=19`: 예측해야 할 클래스의 개수와 동일하게 설정합니다.
    - `activation='softmax'`: **분류 문제에서 가장 중요한 활성화 함수입니다.** 모든 출력값의 합이 1이 되도록 만들어, 각 클래스에 속할 **확률**을 계산해줍니다. 예를 들어, 예측 결과가 `[0.1, 0.7, 0.2]` 라면, 모델은 두 번째 클래스일 확률이 70%로 가장 높다고 예측하는 것입니다.

**2. 모델 학습 과정 설정 (컴파일)**

```python
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
```
- `loss='categorical_crossentropy'`: **다중 클래스 분류 문제에서 사용되는 표준 손실 함수입니다.** 원-핫 인코딩된 정답과 모델의 예측 확률(softmax 결과)을 비교하여 오차를 계산합니다.
- `optimizer='sgd'`: 경사 하강법(Stochastic Gradient Descent)의 한 종류입니다.
- `metrics=['accuracy']`: 모델의 성능을 평가할 지표로 **정확도(accuracy)**를 사용합니다. 전체 데이터 중 모델이 올바르게 예측한 데이터의 비율을 나타냅니다.

### 3.3. 모델 학습 및 평가

**1. 모델 학습**

```python
hist = model.fit(x_train, Y_train, 
                epochs=300,
                batch_size=10, 
                validation_data=(x_val, Y_val))
```
- `batch_size=10`: 한 번에 10개의 데이터를 묶어서 학습하고 가중치를 업데이트합니다. 데이터를 작은 묶음(배치)으로 나누어 학습하면 더 효율적이고 안정적인 학습이 가능합니다.
- `validation_data`: 매 에포크가 끝날 때마다 검증 데이터로 모델의 성능(loss, accuracy)을 평가하여 보여줍니다.

**2. 학습 과정 시각화**

```python
import matplotlib.pyplot as plt

# Train loss vs Validation loss
plt.plot(hist.history['loss'], 'y', label='train loss')
plt.plot(hist.history['val_loss'], 'r', label='val loss')

# Train accuracy vs Validation accuracy
plt.plot(hist.history['accuracy'], 'g', label='train accuracy')
plt.plot(hist.history['val_accuracy'], 'b', label='val accuracy')
```
- 훈련 손실(`loss`)은 계속 감소하는데 검증 손실(`val_loss`)은 어느 순간부터 다시 증가한다면, 모델이 훈련 데이터에만 너무 익숙해져 새로운 데이터를 잘 맞추지 못하는 **과적합(Overfitting)**이 발생하고 있다는 신호입니다.
- 정확도(`accuracy`, `val_accuracy`)는 높을수록 좋습니다.

**3. 모델 평가**

```python
score = model.evaluate(x_test, Y_test)
print('평가된 loss', score[0])
print('평가된 accuracy', score[1]*100, '%')
```
- `evaluate` 함수를 사용해 학습에 사용되지 않은 테스트 데이터로 모델의 최종 성능을 객관적으로 평가합니다.

### 3.4. 모델 사용 및 저장

**1. 예측하기**

```python
# 입력값 2에 대한 예측
prediction = model.predict(np.array([[2]]))

# 예측 결과 중 가장 확률이 높은 클래스의 인덱스 찾기
predicted_class = prediction.argmax()
# 결과: 4
```
- `predict`의 결과는 각 클래스에 대한 확률 배열입니다.
- `argmax()` 함수는 이 배열에서 가장 큰 값의 인덱스를 반환하여, 최종적으로 어떤 클래스로 예측되었는지 알려줍니다.

**2. 모델 저장 및 로드**

```python
# 모델 저장
model.save('./model/02_deep.h5')

# 모델 로드
from tensorflow.keras.models import load_model
model2 = load_model('./model/02_deep.h5')
```
- `save` 함수로 학습된 모델의 구조와 가중치를 모두 파일에 저장할 수 있습니다.
- `load_model` 함수로 저장된 모델을 그대로 불러와 재학습 없이 바로 사용할 수 있습니다.

## 4. 더 깊은 학습을 위한 자료

- **활성화 함수 시각화 및 설명**
  - [https://dasom.io/2021/02/12/activation-function/](https://dasom.io/2021/02/12/activation-function/)
- **손실 함수(Cross-entropy) 설명**
  - [https://goo.gl/X1W3aD](https://goo.gl/X1W3aD)
- **TensorFlow 공식 튜토리얼 (이미지 분류)**
  - [https://www.tensorflow.org/tutorials/images/classification?hl=ko](https://www.tensorflow.org/tutorials/images/classification?hl=ko)

이 문서를 통해 딥러닝 분류 모델의 기본 개념과 전체 과정을 이해하는 데 도움이 되셨기를 바랍니다. 다음 노트북에서는 실제 데이터를 가지고 더 흥미로운 문제들을 해결해 보겠습니다!
