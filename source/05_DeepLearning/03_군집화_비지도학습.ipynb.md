# 비지도 학습: K-평균 군집화 (Unsupervised Learning: K-Means Clustering)

지금까지 우리는 정답이 있는 데이터(지도 학습)를 다루었습니다. 이번에는 한 단계 더 나아가 **정답이 없는 데이터**에서 숨겨진 구조나 패턴을 찾아내는 **비지도 학습(Unsupervised Learning)**에 대해 알아보겠습니다. 그중 가장 대표적인 알고리즘인 **K-평균 군집화(K-Means Clustering)**를 `03_군집화_비지도학습.ipynb` 코드를 통해 배워보겠습니다.

## 1. 비지도 학습과 군집화란?

- **지도 학습 (Supervised Learning)**: 데이터에 '정답' 또는 '레이블'이 붙어 있습니다. (예: 이 사진은 '고양이'다, 이 집의 가격은 '5억'이다)
- **비지도 학습 (Unsupervised Learning)**: 데이터만 있고 정답은 없습니다. 기계가 데이터의 내재된 구조를 스스로 파악하여 비슷한 것끼리 묶거나(군집화), 패턴을 찾아냅니다.

- **군집화 (Clustering)**: 비지도 학습의 가장 대표적인 예입니다. 데이터 포인트들을 비슷한 특성을 가진 몇 개의 그룹(군집, Cluster)으로 묶는 것을 목표로 합니다. 예를 들어, 고객 데이터를 기반으로 비슷한 구매 패턴을 가진 고객 그룹을 찾아내는 마케팅에 활용될 수 있습니다.

## 2. K-평균(K-Means) 알고리즘의 원리

K-평균은 가장 널리 사용되는 군집화 알고리즘 중 하나입니다. 작동 원리는 매우 직관적입니다.

1.  **초기화 (Initialize)**: 데이터를 몇 개의 그룹(K개)으로 나눌지 정한 뒤, K개의 중심점(Centroid)을 임의로 선택합니다.
2.  **할당 (Assign)**: 모든 데이터 포인트를 가장 가까운 중심점에 할당합니다. 이렇게 되면 K개의 군집이 형성됩니다.
3.  **업데이트 (Update)**: 각 군집의 중심점을 해당 군집에 속한 데이터 포인트들의 평균값(무게중심)으로 이동시킵니다.
4.  **반복 (Repeat)**: 2번과 3번 과정을 중심점의 위치가 더 이상 변하지 않을 때까지 반복합니다.

이 노트북에서는 남자와 여자의 키-몸무게 데이터를 생성하고, 이 데이터가 두 개의 그룹으로 자연스럽게 나뉘는 과정을 K-평균 알고리즘을 통해 확인합니다.

## 3. 코드 해설: 단계별로 따라가기

### 3.1. 데이터 생성 및 시각화

```python
import random
import numpy as np
import matplotlib.pyplot as plt

data = []
for i in range(50):
    # 여자 데이터 (몸무게 40~70, 키 140~170)
    data.append([random.randint(40,70), random.randint(140,170)])
    # 남자 데이터 (몸무게 60~95, 키 160~195)
    data.append([random.randint(60, 95), random.randint(160,195)])

# 데이터 시각화
plt.plot([d[0] for d in data[::2]], [d[1] for d in data[::2]], 'o',color='r') # 여자
plt.plot([d[0] for d in data[1::2]], [d[1] for d in data[1::2]], '^',color='b') # 남자
```
- 두 그룹(여성, 남성)의 키와 몸무게 데이터를 무작위로 생성합니다. 각 그룹은 특정 범위 내의 값을 가지므로, 시각화했을 때 자연스럽게 두 개의 덩어리로 나뉘는 것을 볼 수 있습니다.
- 우리는 이 '정답'을 모른다고 가정하고, K-평균 알고리즘이 이 두 그룹을 스스로 찾아내도록 할 것입니다.

### 3.2. K-평균 알고리즘 직접 구현해보기

라이브러리를 사용하기 전에, 알고리즘의 작동 원리를 이해하기 위해 직접 코드를 작성해봅니다.

**1. 초기 중심점 설정 및 거리 계산 함수 정의**

```python
# 1. 초기화: 임의의 중심점 2개 선택
random_points = [[random.randint(40,95), random.randint(140, 195)],
                 [random.randint(40,95), random.randint(140, 195)]]

# 두 점 사이의 유클리드 거리를 계산하는 함수
def dist(a, b):
    return np.sqrt((a[0]-b[0])**2 + (a[1]-b[1])**2)
```

**2. 할당 및 업데이트 과정 반복**

```python
# 10번 반복
for i in range(1, 11):
    # 2. 할당: 각 데이터를 더 가까운 중심점에 따라 group1, group2로 나눔
    group1 = []
    group2 = []
    for d in data:
        if dist(d, points[0]) < dist(d, points[1]):
            group1.append(d)
        else:
            group2.append(d)

    # 3. 업데이트: 각 그룹의 평균 지점으로 중심점을 이동
    # group1의 새로운 중심점
    sumX = sum([g[0] for g in group1])
    sumY = sum([g[1] for g in group1])
    points[0] = [sumX / len(group1), sumY / len(group1)]

    # group2의 새로운 중심점
    sumX = sum([g[0] for g in group2])
    sumY = sum([g[1] for g in group2])
    points[1] = [sumX / len(group2), sumY / len(group2)]
```
- 이 코드는 K-평균 알고리즘의 핵심인 '할당'과 '업데이트'를 10번 반복합니다.
- 반복할수록 중심점(`points`)이 점점 각 그룹의 실제 중심을 향해 안정적으로 이동하는 것을 시각화를 통해 확인할 수 있습니다.

### 3.3. `sklearn` 라이브러리를 이용한 군집화

위에서 직접 구현한 과정을 `scikit-learn`이라는 강력한 머신러닝 라이브러리를 사용하면 단 몇 줄의 코드로 간단하게 수행할 수 있습니다.

```python
from sklearn.cluster import KMeans

data = np.array(data)

# K-Means 모델 생성 및 학습
model = KMeans(n_clusters=2,      # 2개의 그룹으로 나눔
               init='random',     # 초기 중심점을 무작위로 선택
               n_init=10,         # 다른 초기값으로 10번 반복하여 최상의 결과를 선택
               random_state=7)

model.fit(data) # 모델 학습
```
- `KMeans` 객체를 생성하고, 가장 중요한 파라미터인 `n_clusters` (군집의 개수)를 2로 설정합니다.
- `fit()` 함수를 호출하는 것만으로 K-평균 알고리즘의 전체 반복 과정이 수행됩니다.

**학습 결과 확인**

```python
# 최종 중심점 확인
centers = model.cluster_centers_
print(centers)

# 각 데이터가 어떤 그룹에 속하는지 확인 (0 또는 1)
labels = model.labels_
print(labels)
```
- `model.cluster_centers_`: 학습을 통해 찾은 최종 중심점의 좌표를 보여줍니다.
- `model.labels_`: 각 데이터 포인트가 0번 군집과 1번 군집 중 어디에 할당되었는지를 배열 형태로 보여줍니다.

이 결과를 이용해 데이터를 각 그룹별로 색칠하여 시각화하면, K-평균 알고리즘이 성공적으로 두 그룹을 구분해 냈음을 확인할 수 있습니다.

## 4. 더 깊은 학습을 위한 자료

- **K-평균 알고리즘 시각적 설명 (강력 추천)**
  - StatQuest - k-means clustering: [https://www.youtube.com/watch?v=4b5d3muPQmA](https://www.youtube.com/watch?v=4b5d3muPQmA)
- **Scikit-Learn 공식 문서**
  - `sklearn.cluster.KMeans`: [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- **최적의 K값 찾기 (Elbow Method)**
  - K-평균 군집에서 최적의 K를 찾는 방법: [https://vitalflux.com/k-means-clustering-finding-optimal-number-clusters/](https://vitalflux.com/k-means-clustering-finding-optimal-number-clusters/)

이번 장을 통해 비지도 학습과 군집화의 기본 개념을 이해하셨기를 바랍니다. 정답이 없는 데이터 속에서 의미 있는 패턴을 찾아내는 것은 데이터 과학의 매우 흥미로운 분야입니다.
