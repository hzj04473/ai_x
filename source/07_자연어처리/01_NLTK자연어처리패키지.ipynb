{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(\n",
    "    HTML(\"\"\"\n",
    "<style>\n",
    "* {font-family:D2Coding;}\n",
    "div.container{width:87% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.CodeMirror {font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input { font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:3px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e02a6c",
   "metadata": {},
   "source": [
    "# <span style='color:red'>Ch1. NLTK 자연어처리 패키지</span>\n",
    "\n",
    "# 1. NLTK 패키지\n",
    "\n",
    "- 자연어처리를 위한 강력하고, 사용하기 쉬운 라이브러리\n",
    "  \n",
    "1. 텍스트 전처리 : 토큰화(어절, 문장나누기), 정규화(정규표현식 활용), 불용어 제거, 표제어 추출 (기본형태로 변환)\n",
    "2. 품사태킹 : 단어 품사 식별\n",
    "3. 어휘 데이터 베이스 사용\n",
    "4. 구조화된 문서의 빈도수, 분류분석, 연관분석, 감정분석 (단점) 속도가 느림\n",
    "   - 그래서 pip install nltk==3.7 설치\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85f3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f12d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치를 다운로드\n",
    "# c:/nltk_data\n",
    "# d:/nltk_data\n",
    "# c:/Users/내컴퓨터이름/nltk_data\n",
    "# c:/Users/내컴퓨터이름/anaconda3/nltk_data\n",
    "# c:/Users/내컴퓨터이름/anaconda3/lib/nltk_data\n",
    "# c:/Users/내컴퓨터이름/anaconda3/share/nltk_data\n",
    "# c:/Users/내컴퓨터이름/Appdata/Roaming/nltk_data\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc985094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc57250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치 리스트\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99df3a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCH'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치 데이터 셋 (소설 엠마내용)\n",
    "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "emma[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799c284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수 : 887071\n"
     ]
    }
   ],
   "source": [
    "# 말뭉치 글자수, 문장수, 단어수\n",
    "print('글자수 :', len(emma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef266f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장수 :  7456\n",
      "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.'\n"
     ]
    }
   ],
   "source": [
    "# sent_tokenize() : 문장단위로 나눠 list 반환\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokens = sent_tokenize(emma)\n",
    "sent_tokens[:3]\n",
    "\n",
    "print('문장수 : ', len(sent_tokens))\n",
    "print(\"%r\" % sent_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b69765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.']\n"
     ]
    }
   ],
   "source": [
    "# word_tokenize() : 단어토큰으로 쪼갠 list 반환\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(word_tokenize(sent_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e09351fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어수 : 191776\n"
     ]
    }
   ],
   "source": [
    "print(\"단어수 :\", len(word_tokenize(emma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3bc821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1816']\n",
      "['Emma', 'by', 'Jane', 'Austen', '1816', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her']\n"
     ]
    }
   ],
   "source": [
    "# RegexpTokenizer() : 토큰화할 떄 해당 정규표현식에 해당하는 word만 적용\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "digiRet = RegexpTokenizer('\\d+') # 숫자만\n",
    "alphaRet = RegexpTokenizer('\\w+') # 글자만\n",
    "\n",
    "digis = digiRet.tokenize(sent_tokens[0])\n",
    "print(digis) \n",
    "\n",
    "words = alphaRet.tokenize(sent_tokens[0])\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc9aa3",
   "metadata": {},
   "source": [
    "# 2. 형태소 (의미 있는 가장 작은 단위) 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c2fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'send'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = ['sending','cooking','files','lives','crying','dying']\n",
    "\n",
    "# 어간추출(1) : PorterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "pst = PorterStemmer()\n",
    "pst.stem(words2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a22a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b785e3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'file', 'live', 'cri', 'die']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ pst.stem(word) for word in words2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a2c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'fil', 'liv', 'cry', 'dying']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어간추출(2) : LancasterStemmer() 어간 추출하는 것 중 제일 빈도 높다\n",
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "\n",
    "[lst.stem(word) for word in words2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdb23df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'files', 'lives', 'cry', 'dy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어간 추출(3) : RegexpStemmer 정규표현식에 해당하는 부분만 어간 추출\n",
    "from nltk.stem import RegexpStemmer\n",
    "rst = RegexpStemmer('ing')\n",
    "[rst.stem(word) for word in words2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f96bf3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.']\n",
      "품사태킹한 결과 [('[', 'NNS'), ('Emma', 'NNP'), ('by', 'IN'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('1816', 'CD'), (']', 'NNP'), ('VOLUME', 'NNP'), ('I', 'PRP'), ('CHAPTER', 'VBP'), ('I', 'PRP'), ('Emma', 'NNP'), ('Woodhouse', 'NNP'), (',', ','), ('handsome', 'NN'), (',', ','), ('clever', 'NN'), (',', ','), ('and', 'CC'), ('rich', 'JJ'), (',', ','), ('with', 'IN'), ('a', 'DT'), ('comfortable', 'JJ'), ('home', 'NN'), ('and', 'CC'), ('happy', 'JJ'), ('disposition', 'NN'), (',', ','), ('seemed', 'VBD'), ('to', 'TO'), ('unite', 'VB'), ('some', 'DT'), ('of', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('blessings', 'NNS'), ('of', 'IN'), ('existence', 'NN'), (';', ':'), ('and', 'CC'), ('had', 'VBD'), ('lived', 'VBN'), ('nearly', 'RB'), ('twenty-one', 'CD'), ('years', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('with', 'IN'), ('very', 'RB'), ('little', 'JJ'), ('to', 'TO'), ('distress', 'VB'), ('or', 'CC'), ('vex', 'VB'), ('her', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# 품사태킹\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "trgged_list = pos_tag(word_tokenize(sent_tokens[0]))\n",
    "print(word_tokenize(sent_tokens[0]))\n",
    "print('품사태킹한 결과', trgged_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1d2e6",
   "metadata": {},
   "source": [
    "## 퀴즈 : emma 소설안에서\n",
    "1. 특수문자가 들어가지 않은 3글자 이상 되는 단어만 추출해서 폼사태킹을 하시요.\n",
    "   - ex) [('emma', '명사'), ('was','동')...]\n",
    "2. \"Emma\" 단어가 몇번 등장하며, 품사태킹이 어떤 품사들로 되어 있는지 모두 출력하시오.\n",
    "3. 내가 원하는 품사(명사)의 단어만 뽑아 등장하는 명사의 종류 갯수를 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e724a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma 소설에서 3글자 이상의 단어 출현수 :  123877 123877\n",
      "emma 소설에서 3글자 이상의 단어 종류수 :  7630 11678\n",
      "CPU times: user 2.46 s, sys: 34.9 ms, total: 2.5 s\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# 1. 특수문자가 들어가지 않은 3글자 이상 되는 단어만 추출해서 폼사태킹을 하시요.\n",
    "\n",
    "ret = RegexpTokenizer('\\w{3,}') # 글자만\n",
    "\n",
    "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "emma_words = ret.tokenize(emma)\n",
    "emma_tags = pos_tag(emma_word)\n",
    "\n",
    "# print(emma_tags)\n",
    "\n",
    "print('emma 소설에서 3글자 이상의 단어 출현수 : ', len(emma_word), len(emma_tags))\n",
    "print('emma 소설에서 3글자 이상의 단어 종류수 : ', len(set(emma_word)), len(set(emma_tags)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93940455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'Jane', 'Austen', '1816', 'VOLUME']\n",
      "[('Emma', 'NNP'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('1816', 'CD'), ('VOLUME', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(emma_word[:5])\n",
    "print(emma_tags[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd3a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma 출현횟수 :  865\n",
      "Emma의 품사 : {'JJ', 'NNP', 'NNS', 'VBP', 'RB', 'NN', 'VBN', 'VB', 'VBD', 'NNPS'}\n"
     ]
    }
   ],
   "source": [
    "# 2. \"Emma\" 단어가 몇번 등장하며, 품사태킹이 어떤 품사들로 되어 있는지 모두 출력하시오.\n",
    "pos = [] # 품사만\n",
    "for emma_tag in emma_tags:\n",
    "    if emma_tag[0] == 'Emma':\n",
    "        pos.append(emma_tag[1])\n",
    "    \n",
    "print('Emma 출현횟수 : ', len(pos))\n",
    "print('Emma의 품사 :', set(pos))\n",
    "# Emma 출현횟수 :  865\n",
    "# {'JJ', 'NNP', 'NNS', 'VBP', 'RB', 'NN', 'VBN', 'VB', 'VBD', 'NNPS'}\n",
    "# 동사과거형, 동사, 고유명사복수, 동사, 고유명사, 형툥사, 명사, 동사과거분사, 형용사, 명사복수형\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1a5068e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NNP': 838,\n",
       " 'VBP': 4,\n",
       " 'JJ': 4,\n",
       " 'VB': 5,\n",
       " 'NNS': 2,\n",
       " 'RB': 1,\n",
       " 'NN': 7,\n",
       " 'NNPS': 2,\n",
       " 'VBN': 1,\n",
       " 'VBD': 1}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emma_tags에서 각 품사별 몇개씩 포스태그 되었는지?\n",
    "# set(pos) # emma를 품사\n",
    "pos_cnt = dict()\n",
    "\n",
    "for word, tag in emma_tags:\n",
    "    if word == 'Emma':\n",
    "        if tag in pos_cnt:\n",
    "            pos_cnt[tag] +=1\n",
    "        else:\n",
    "            pos_cnt[tag] = 1\n",
    "pos_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e2ba4e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNP     838\n",
       "NN        7\n",
       "VB        5\n",
       "JJ        4\n",
       "VBP       4\n",
       "NNS       2\n",
       "NNPS      2\n",
       "RB        1\n",
       "VBN       1\n",
       "VBD       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pos_cnt = pd.Series([0]*len(set(pos)), index=set(pos))\n",
    "\n",
    "for word, tag in emma_tags:\n",
    "    if word == 'Emma':\n",
    "        if tag in pos_cnt:\n",
    "            pos_cnt[tag] +=1\n",
    "pos_cnt.sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bafb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dd337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb4905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f309a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6fe64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3f1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58a4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db1432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe30c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604cda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7e496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815f655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861a3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
