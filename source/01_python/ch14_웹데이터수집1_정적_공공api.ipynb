{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55784b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "* {font-family:D2Coding;}\n",
       "div.container{width:87% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.CodeMirror {font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input { font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:3px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\"\"\"\n",
    "<style>\n",
    "* {font-family:D2Coding;}\n",
    "div.container{width:87% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.CodeMirror {font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input { font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:3px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad6cb7",
   "metadata": {},
   "source": [
    "<b><font size=\"5\" color=\"red\">ch14_웹데이터 수집</font></b>\n",
    "\n",
    "# 1절. BeautifulSoup과 parser\n",
    "\n",
    "```pip install bs4``` 아나콘다를 설치하면 7500개여개의 패키지 설치\n",
    "- [BeautifulSoup 공식사이트] : https://www.crummy.com/software/BeautifulSoup/\n",
    "- [BeautifulSoup 공식문서] : https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "922f9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/requests/\n",
    "import requests # HTTP 요청 처리 lib\n",
    "\n",
    "# https://pypi.org/project/requests-file/\n",
    "from requests_file import FileAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "055c44d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "s = requests.Session() # HTTP 요청관리를 위한 세션 객체\n",
    "s.mount(\"file://\", FileAdapter())\n",
    "# print(s)\n",
    "response = s.get('file:///Volumes/DATA/mbc/ai_x/source/01_python/data/ch14_sample.html')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b56dc267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code\n",
    "#200 : 정상\n",
    "#404 : 없는페이지 오류\n",
    "#406 : get, post 오류\n",
    "#500 : 파이썬 문법 오류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f548917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n  <head>\\r\\n    <meta charset=\"UTF-8\" />\\r\\n  </head>\\r\\n  <body>\\r\\n    <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\\r\\n    <h1 class=\"css\">Hi, CSS</h1>\\r\\n    <div id=\"subject\">subject \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90 \\xec\\x95\\x88\\xec\\x9d\\x98 \\xeb\\x82\\xb4\\xec\\x9a\\xa9</div>\\r\\n    <p>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90\\xec\\x84\\x9c \\xed\\x99\\x9c\\xec\\x9a\\xa9\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</p>\\r\\n    <div class=\"contents\">\\r\\n      \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\xa5\\xbc \\xec\\x96\\xb4\\xeb\\x96\\xbb\\xea\\xb2\\x8c \\xec\\x9e\\x91\\xec\\x84\\xb1\\xed\\x95\\x98\\xeb\\x8a\\x90\\xeb\\x83\\x90\\xec\\x97\\x90 \\xeb\\x94\\xb0\\xeb\\x9d\\xbc\\r\\n      <span>\\xeb\\x8b\\xa4\\xeb\\xa5\\xb8<b>\\xec\\x9a\\x94\\xec\\x86\\x8c\\xea\\xb0\\x80 \\xeb\\xb0\\x98\\xed\\x99\\x98</b></span\\r\\n      >\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4\\r\\n    </div>\\r\\n    <div>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90 <b>\\xed\\x99\\x9c\\xec\\x9a\\xa9</b>\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</div>\\r\\n  </body>\\r\\n</html>\\r\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content # 바이너리 형식의 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6425c673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n  <head>\\r\\n    <meta charset=\"UTF-8\" />\\r\\n  </head>\\r\\n  <body>\\r\\n    <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\\r\\n    <h1 class=\"css\">Hi, CSS</h1>\\r\\n    <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n    <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n    <div class=\"contents\">\\r\\n      선택자를 어떻게 작성하느냐에 따라\\r\\n      <span>다른<b>요소가 반환</b></span\\r\\n      >됩니다\\r\\n    </div>\\r\\n    <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n  </body>\\r\\n</html>\\r\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5d11e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n  <head>\\r\\n    <meta charset=\"UTF-8\" />\\r\\n  </head>\\r\\n  <body>\\r\\n    <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\\r\\n    <h1 class=\"css\">Hi, CSS</h1>\\r\\n    <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n    <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n    <div class=\"contents\">\\r\\n      선택자를 어떻게 작성하느냐에 따라\\r\\n      <span>다른<b>요소가 반환</b></span\\r\\n      >됩니다\\r\\n    </div>\\r\\n    <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n  </body>\\r\\n</html>\\r\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode('utf-8') 와 같아서,\n",
    "# 앞으로 이걸로 크롤링을 할 예정\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f656263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "</head>\n",
       "<body>\n",
       "<h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\n",
       "<h1 class=\"css\">Hi, CSS</h1>\n",
       "<div id=\"subject\">subject 선택자 안의 내용</div>\n",
       "<p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\n",
       "<div class=\"contents\">\n",
       "      선택자를 어떻게 작성하느냐에 따라\n",
       "      <span>다른<b>요소가 반환</b></span>됩니다\n",
       "    </div>\n",
       "<div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html 파싱\n",
    "from bs4 import BeautifulSoup\n",
    "# 객체 생성\n",
    "soup = BeautifulSoup(response.content, \"html.parser\") # 또는 response.text\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6315e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 : <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\n",
      "e1.text : Hello, CSS\n",
      "e1.string : Hello, CSS\n",
      "e1의 속성들 : {'class': ['greeting', 'css'], 'id': 'text', 'title': 'greeting'}\n",
      "e1의 title 속성 : greeting\n",
      "e1의 title 속성 : greeting\n",
      "e1의 이름 : h1\n"
     ]
    }
   ],
   "source": [
    "# soup.select_one('선택자') : 해당 선택자 처음 하나만\n",
    "e1 = soup.select_one('h1'); # ★ 처음 나오는 h1태그 하나만\n",
    "print('e1 :', e1) # ★\n",
    "print('e1.text :', e1.text) # ★\n",
    "print('e1.string :', e1.string)\n",
    "print('e1의 속성들 :', e1.attrs)\n",
    "print('e1의 title 속성 :', e1.attrs['title'])\n",
    "print('e1의 title 속성 :', e1.attrs.get('title')) # ★ 딕셔너리는 이렇게 가져 오는 것이 더 좋다.\n",
    "print('e1의 이름 :', e1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3604ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리스트 el :  [<h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "el의 text들 :  ['Hello, CSS', 'Hi, CSS']\n",
      "el의 속성들 :  [{'class': ['greeting', 'css'], 'id': 'text', 'title': 'greeting'}, {'class': ['css']}]\n",
      "el의 class속성들 :  [['greeting', 'css'], ['css']]\n"
     ]
    }
   ],
   "source": [
    "# soup.select('선택자') : 해당 선택자 모든 엘리먼트를 리스트로\n",
    "el = soup.select('h1')\n",
    "\n",
    "\n",
    "print('리스트 el : ', el)\n",
    "print('el의 text들 : ',[e.text for e in el])\n",
    "# for e in el:\n",
    "#     print(e.text, end=',')\n",
    "print('el의 속성들 : ',[e.attrs for e in el])\n",
    "print('el의 class속성들 : ',[ e.attrs.get('class') for e in el ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b962ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soup.select_one : <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\n",
      "soup.find : <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\n",
      "soup.find : <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\n",
      "\n",
      "soup.select_one <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\n",
      "soup.find <h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>\n",
      "\n",
      "soup.select\n"
     ]
    }
   ],
   "source": [
    "# soup.select_one(선택자) 와 soup.find(태그, 속성)\n",
    "print('soup.select_one :', soup.select_one('h1.css'))\n",
    "print('soup.find :', soup.find('h1',{'class':'css'}))\n",
    "print('soup.find :', soup.find('h1', class_='css')) # class만 가능\n",
    "print()\n",
    "print('soup.select_one',soup.select_one('h1#text'))\n",
    "print('soup.find',soup.find('h1', {'id':'text'}))\n",
    "print()\n",
    "print('soup.select')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "190ae420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 h1.css, span 태그 (select) : [<h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>, <span>다른<b>요소가 반환</b></span>]\n",
      "모든 h1.css, span 태그 (find_all) : [<h1 class=\"greeting css\" id=\"text\" title=\"greeting\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n"
     ]
    }
   ],
   "source": [
    "# select(선택자)와 find_all(태그, 속성)\n",
    "print('모든 h1.css, span 태그 (select) :', soup.select('h1.css, span'))\n",
    "print('모든 h1.css, span 태그 (find_all) :', soup.find_all(['h1','span'], class_='css'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a57e2022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_all : []\n",
      "find : None\n",
      "select []\n",
      "select_one None\n"
     ]
    }
   ],
   "source": [
    "# 없는 엘리먼트 찾기\n",
    "print('find_all :', soup.find_all('a', class_='css')) # 빈 리스트\n",
    "print('find :', soup.find('a', class_='css')) # None\n",
    "print('select', soup.select('a.css'))\n",
    "print('select_one', soup.select_one('a.css'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483ebe8",
   "metadata": {},
   "source": [
    "<h1>2절. 정적 웹 데이터 수집 (정적 웹크롤링)</h1>\n",
    "\n",
    "- json\n",
    "- xml, html : select_one, select, find, find_all 가능\n",
    "\n",
    "<h2>2-1. JSON파일</h2>\n",
    "\n",
    "- requests모듈(get)\n",
    "- urllib.request모듈(urlopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 허용 범위는 사이트마다 ~/robots.txt 에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2d054ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "import json\n",
    "# response = requests.get('https://api.github.com')\n",
    "# response, response.status_code\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bbf9518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "# response = urlopen('https://api.github.com')\n",
    "# response.status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "06c26dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '{\"속성1\":\"값1\", \"속성2\":\"값2\"}'\n",
    "\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "47bec843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'속성1': '값1', '속성2': '값2'}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자(딕셔너리 타입)를 딕셔너리로\n",
    "# '{\"속성1\":\"값1\", \"속성2\":\"값2\"}' => {\"속성1\":\"값1\", \"속성2\":\"값2\"}\n",
    "import json\n",
    "json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207211d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba13573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb4239bd",
   "metadata": {},
   "source": [
    "## 2-2. html 파일\n",
    "\n",
    "### 1) 환율정보 가져오기 (네이버 → 증권 → 시장지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dff2e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "response = requests.get(url)\n",
    "# response, response.status_code\n",
    "# response.content (바이너리)\n",
    "# response.content.decode('cp949') == response.text\n",
    "\n",
    "soup = BeautifulSoup(response.text,'html.parser') # 또는 response.content\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "309a2e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "response = urlopen(url)\n",
    "# response.status 상태코드\n",
    "# response.read()\n",
    "# response.read().decode('cp949')\n",
    "soup = BeautifulSoup(response, 'html.parser') # 또는 response.read()\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dd2abb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['미국 USD', '일본 JPY(100엔)', '유럽연합 EUR', '중국 CNY', '달러/일본 엔', '유로/달러', '영국 파운드/달러', '달러인덱스', 'WTI', '휘발유', '국제 금', '국내 금']\n",
      "['1,373.90', '952.28', '1,555.05', '190.92', '1.1342', '1.3520', '60.89', '1633.17', '3300.4']\n"
     ]
    }
   ],
   "source": [
    "title = soup.select(\"h3.h_lst > span.blind\")\n",
    "[t.text for t in title]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e9bf5065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1374, 952, 1555, 191, 144, 1, 1, 99, 61, 1633, 3300, 146245]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = soup.select(\"div.head_info > span.value\")\n",
    "[p.text for p in price]\n",
    "[round(float(p.text.replace(',',''))) for p in price]\n",
    "[round(float(''.join(p.text.split(',')))) for p in price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ca48d0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ',' 빼는 법\n",
    "\n",
    "out = '1,373.90'\n",
    "# 1번쨰\n",
    "round(float(''.join(out.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9e4acb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2번쨰\n",
    "round(float(out.replace(',','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "826e647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['원', '원', '원', '원', '엔', '달러', '달러', '', '달러', '원', '달러', '원']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit = soup.select('div.head_info > span > span.blind')\n",
    "unit = [u.text for u in unit]\n",
    "unit.insert(7, '') # 7번째 index에 '' 추가\n",
    "unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9d4c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하락', '하락', '하락', '하락', '상승', '하락', '하락', '상승', '하락', '하락', '하락', '상승']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = soup.select('div.head_info > span.blind')\n",
    "\n",
    "[t.text for t in title]\n",
    "[p.text for p in price]\n",
    "unit\n",
    "[s.text for s in status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b4e9a02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 12, 12)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title), len(price), len(unit), len(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ede56667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.미국 USD : 1,373.90원 - 하락\n",
      "2.일본 JPY(100엔) : 952.28원 - 하락\n",
      "3.유럽연합 EUR : 1,555.05원 - 하락\n",
      "4.중국 CNY : 190.92원 - 하락\n",
      "5.달러/일본 엔 : 144.3800엔 - 상승\n",
      "6.유로/달러 : 1.1342달러 - 하락\n",
      "7.영국 파운드/달러 : 1.3520달러 - 하락\n",
      "8.달러인덱스 : 99.4200 - 상승\n",
      "9.WTI : 60.89달러 - 하락\n",
      "10.휘발유 : 1633.17원 - 하락\n",
      "11.국제 금 : 3300.4달러 - 하락\n",
      "12.국내 금 : 146244.92원 - 상승\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(title)):\n",
    "    print(\"{}.{} : {}{} - {}\".format(idx+1, title[idx].text, price[idx].text, unit[idx], status[idx].text ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6cc05ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD: 1,373.90원 - 하락\n",
      "일본 JPY(100엔): 952.28원 - 하락\n",
      "유럽연합 EUR: 1,555.05원 - 하락\n",
      "중국 CNY: 190.92원 - 하락\n",
      "달러/일본 엔: 144.3800엔 - 상승\n",
      "유로/달러: 1.1342달러 - 하락\n",
      "영국 파운드/달러: 1.3520달러 - 하락\n",
      "달러인덱스: 99.4200 - 상승\n",
      "WTI: 60.89달러 - 하락\n",
      "휘발유: 1633.17원 - 하락\n",
      "국제 금: 3300.4달러 - 하락\n",
      "국내 금: 146244.92원 - 상승\n"
     ]
    }
   ],
   "source": [
    "# zip 함수 이용\n",
    "for t, p, u, s in zip(title, price, unit, status) :\n",
    "    print(\"{}: {}{} - {}\".format(t.text, p.text, u, s.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "55b1392f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 미국 USD: 1,373.90원 - 하락\n",
      "2. 일본 JPY(100엔): 952.28원 - 하락\n",
      "3. 유럽연합 EUR: 1,555.05원 - 하락\n",
      "4. 중국 CNY: 190.92원 - 하락\n",
      "5. 달러/일본 엔: 144.3800엔 - 상승\n",
      "6. 유로/달러: 1.1342달러 - 하락\n",
      "7. 영국 파운드/달러: 1.3520달러 - 하락\n",
      "8. 달러인덱스: 99.4200 - 상승\n",
      "9. WTI: 60.89달러 - 하락\n",
      "10. 휘발유: 1633.17원 - 하락\n",
      "11. 국제 금: 3300.4달러 - 하락\n",
      "12. 국내 금: 146244.92원 - 상승\n"
     ]
    }
   ],
   "source": [
    "for idx, (t, p, u, s) in enumerate(zip(title, price, unit, status)) :\n",
    "    print(\"{}. {}: {}{} - {}\".format(idx+1,t.text, p.text, u, s.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad2290",
   "metadata": {},
   "source": [
    "### 2) 이번주 로또번호 출력\n",
    "\n",
    "- https://dhlottery.co.kr/gameResult.do?method=byWin&wiselog=H_C_1_1 \n",
    "\n",
    "```\n",
    "1173회(2025년 05월 24일 추첨)\n",
    "당첨번호 [1 5 18 20 30 35]\n",
    "보너스 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4b2352a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173회 (2025년 05월 24일 추첨)\n",
      "당첨번호 ['1', '5', '18', '20', '30', '35']\n",
      "보너스 3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin&wiselog=H_C_1_1'\n",
    "response = requests.get(url)\n",
    "# response.status_code\n",
    "\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "title = soup.select_one('div.win_result > h4 > strong').text\n",
    "desc = soup.select_one('div.win_result > p.desc').text\n",
    "title1 = soup.select_one('div.win_result > div.nums > div.win strong').text\n",
    "ball = soup.select('div.win_result > div.nums > div.win p > span')\n",
    "ball = [b.text for b in ball]\n",
    "\n",
    "title2 = soup.select_one('div.win_result > div.nums > div.bonus > strong').text\n",
    "bonus = soup.select_one('div.win_result > div.nums > div.bonus > p > span').text\n",
    "\n",
    "print('{} {}'.format(title, desc))\n",
    "print('{} {}'.format(title1, ball))\n",
    "print('{} {}'.format(title2, bonus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16f0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173회 (2025년 05월 24일 추첨)\n",
      "당첨번호 [1, 5, 18, 20, 30, 35]\n",
      "보너스 3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin&wiselog=H_C_1_1'\n",
    "response = requests.get(url)\n",
    "# response.status_code\n",
    "\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "win_result = soup.find('div', class_='win_result')\n",
    "# print(win_result)\n",
    "\n",
    "times = win_result.find('strong').text\n",
    "\n",
    "# times\n",
    "date = soup.find('p',class_='desc').text\n",
    "\n",
    "print(times, date)\n",
    "\n",
    "num_win = soup.find('div',class_=['num','win'])\n",
    "# num_win\n",
    "\n",
    "title1 = num_win.find('strong').text\n",
    "lotto_number = num_win.find_all('span') #배열\n",
    "\n",
    "print(title1, [int(lotto.text) for lotto in lotto_number])\n",
    "\n",
    "num_bonus = soup.find('div', class_=['bonus'])\n",
    "\n",
    "# num_bonus\n",
    "title2 = num_bonus.find('strong').text\n",
    "bonus_number = num_bonus.find('span').text\n",
    "print(title2, bonus_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acee8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173회 (2025년 05월 24일 추첨)\n",
      "당첨번호 ['1', '5', '18', '20', '30', '35']\n",
      "보너스 3\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin&wiselog=H_C_1_1'\n",
    "response = urlopen(url)\n",
    "# response.status\n",
    "\n",
    "soup = BeautifulSoup(response,'html.parser')\n",
    "# soup\n",
    "\n",
    "title = soup.select_one('div.win_result > h4 > strong').text\n",
    "desc = soup.select_one('div.win_result > p.desc').text\n",
    "title1 = soup.select_one('div.win_result > div.nums > div.win strong').text\n",
    "ball = soup.select('div.win_result > div.nums > div.win p > span')\n",
    "ball = [b.text for b in ball]\n",
    "title2 = soup.select_one('div.win_result > div.nums > div.bonus > strong').text\n",
    "bonus = soup.select_one('div.win_result > div.nums > div.bonus > p > span').text\n",
    "\n",
    "print('{} {}'.format(title, desc))\n",
    "print('{} {}'.format(title1, ball))\n",
    "print('{} {}'.format(title2, bonus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f0f207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173회 (2025년 05월 24일 추첨)\n",
      "당첨번호 [1, 5, 18, 20, 30, 35]\n",
      "보너스 3\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin&wiselog=H_C_1_1'\n",
    "response = urlopen(url)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "win_result = soup.find('div', class_='win_result')\n",
    "# print(win_result)\n",
    "\n",
    "times = win_result.find('strong').text\n",
    "\n",
    "# times\n",
    "date = soup.find('p',class_='desc').text\n",
    "\n",
    "print(times, date)\n",
    "\n",
    "num_win = soup.find('div',class_=['num','win'])\n",
    "# num_win\n",
    "\n",
    "title1 = num_win.find('strong').text\n",
    "lotto_number = num_win.find_all('span') #배열\n",
    "\n",
    "print(title1, [int(lotto.text) for lotto in lotto_number])\n",
    "\n",
    "num_bonus = soup.find('div', class_=['bonus'])\n",
    "\n",
    "# num_bonus\n",
    "title2 = num_bonus.find('strong').text\n",
    "bonus_number = num_bonus.find('span').text\n",
    "print(title2, bonus_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db0564",
   "metadata": {},
   "source": [
    "### 3) 다음 검색 리스트\n",
    "\n",
    "```\n",
    "no   title                                                                  link\n",
    "0    [비트코인 2025] 백악관 크립토 차르 “美 정부 비트코인 추가 매입 검토…부채 안 늘리면 가능  https://v.daum.net/v/20250528103907230\n",
    "1    [비즈 나우] 비트코인 2025 컨퍼런스 개막…'전략자산' 선언 코앞                      https://v.daum.net/v/20250528075215864 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "66f8a30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[비트코인 2025] 백악관 크립토 차르 “美 정부 비트코인 추가 매입 검토…부채...</td>\n",
       "      <td>http://v.daum.net/v/20250528103907230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[비즈 나우] 비트코인 2025 컨퍼런스 개막…'전략자산' 선언 코앞</td>\n",
       "      <td>http://v.daum.net/v/20250528075215864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>“맥O날드보다 맛없어!” 혹평이 가득한 트럼프 만찬과 비트코인 피자데이[엠블록레터]</td>\n",
       "      <td>http://v.daum.net/v/20250528143002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>블랙록, 자사 비트코인 ETF 보유량 25% 확대…기관 투자 본격화 신호탄</td>\n",
       "      <td>http://v.daum.net/v/20250528151802080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>비트코인, 트럼프 미디어 비축 소식에도 주춤…1억5100만원대</td>\n",
       "      <td>http://v.daum.net/v/20250528095112897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>'비트코인 빚투' 스트레티지, 또 샀다…보유량 58만개 돌파</td>\n",
       "      <td>http://v.daum.net/v/20250528042404292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>美 상원의원 \"트럼프 대통령, 비트코인법 지지\"</td>\n",
       "      <td>http://v.daum.net/v/20250528090342853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>숨 고르는 비트코인, 10만8000달러선 '주춤'</td>\n",
       "      <td>http://v.daum.net/v/20250528095921258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[비트코인 2025] 로빈후드 창업자 “토큰화 증권은 美 ‘자본 패권’ 키우는 수단”</td>\n",
       "      <td>http://v.daum.net/v/20250528110600761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>트럼프미디어그룹, 25억 달러 규모 자금 조달 통해 비트코인 매입 예고</td>\n",
       "      <td>http://v.daum.net/v/20250528084245020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   0   [비트코인 2025] 백악관 크립토 차르 “美 정부 비트코인 추가 매입 검토…부채...   \n",
       "1   1            [비즈 나우] 비트코인 2025 컨퍼런스 개막…'전략자산' 선언 코앞    \n",
       "2   2    “맥O날드보다 맛없어!” 혹평이 가득한 트럼프 만찬과 비트코인 피자데이[엠블록레터]    \n",
       "3   3         블랙록, 자사 비트코인 ETF 보유량 25% 확대…기관 투자 본격화 신호탄    \n",
       "4   4                비트코인, 트럼프 미디어 비축 소식에도 주춤…1억5100만원대    \n",
       "5   5                 '비트코인 빚투' 스트레티지, 또 샀다…보유량 58만개 돌파    \n",
       "6   6                        美 상원의원 \"트럼프 대통령, 비트코인법 지지\"    \n",
       "7   7                       숨 고르는 비트코인, 10만8000달러선 '주춤'    \n",
       "8   8   [비트코인 2025] 로빈후드 창업자 “토큰화 증권은 美 ‘자본 패권’ 키우는 수단”    \n",
       "9   9           트럼프미디어그룹, 25억 달러 규모 자금 조달 통해 비트코인 매입 예고    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20250528103907230  \n",
       "1  http://v.daum.net/v/20250528075215864  \n",
       "2  http://v.daum.net/v/20250528143002735  \n",
       "3  http://v.daum.net/v/20250528151802080  \n",
       "4  http://v.daum.net/v/20250528095112897  \n",
       "5  http://v.daum.net/v/20250528042404292  \n",
       "6  http://v.daum.net/v/20250528090342853  \n",
       "7  http://v.daum.net/v/20250528095921258  \n",
       "8  http://v.daum.net/v/20250528110600761  \n",
       "9  http://v.daum.net/v/20250528084245020  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "word = '비트코인'\n",
    "url = \"https://search.daum.net/search?w=news&nil_search=btn&DA=NTB&enc=utf8&cluster=y&cluster_page=1&q=\"+word\n",
    "\n",
    "response = requests.get(url)\n",
    "response, response.status_code\n",
    "\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "items_find_list = [] # 검색한 결과를 담는 dict list\n",
    "\n",
    "item_el = soup.select('div.item-title > strong.tit-g.clamp-g > a')\n",
    "\n",
    "len(item_el)\n",
    "\n",
    "for idx, item in enumerate(item_el):\n",
    "    # print(idx, item.text, item.attrs['href'])\n",
    "    # print(idx, item.text, item.attrs.get('href'))\n",
    "    items_find_list.append({'no':idx, 'title':item.text, 'link':item.attrs.get('href')})\n",
    "\n",
    "pd.DataFrame(items_find_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9dacdfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[비트코인 2025] 백악관 크립토 차르 “美 정부 비트코인 추가 매입 검토…부채...</td>\n",
       "      <td>http://v.daum.net/v/20250528103907230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[비즈 나우] 비트코인 2025 컨퍼런스 개막…'전략자산' 선언 코앞</td>\n",
       "      <td>http://v.daum.net/v/20250528075215864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>“맥O날드보다 맛없어!” 혹평이 가득한 트럼프 만찬과 비트코인 피자데이[엠블록레터]</td>\n",
       "      <td>http://v.daum.net/v/20250528143002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>블랙록, 자사 비트코인 ETF 보유량 25% 확대…기관 투자 본격화 신호탄</td>\n",
       "      <td>http://v.daum.net/v/20250528151802080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>비트코인, 트럼프 미디어 비축 소식에도 주춤…1억5100만원대</td>\n",
       "      <td>http://v.daum.net/v/20250528095112897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>'비트코인 빚투' 스트레티지, 또 샀다…보유량 58만개 돌파</td>\n",
       "      <td>http://v.daum.net/v/20250528042404292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>美 상원의원 \"트럼프 대통령, 비트코인법 지지\"</td>\n",
       "      <td>http://v.daum.net/v/20250528090342853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>숨 고르는 비트코인, 10만8000달러선 '주춤'</td>\n",
       "      <td>http://v.daum.net/v/20250528095921258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[비트코인 2025] 로빈후드 창업자 “토큰화 증권은 美 ‘자본 패권’ 키우는 수단”</td>\n",
       "      <td>http://v.daum.net/v/20250528110600761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>트럼프미디어그룹, 25억 달러 규모 자금 조달 통해 비트코인 매입 예고</td>\n",
       "      <td>http://v.daum.net/v/20250528084245020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   0   [비트코인 2025] 백악관 크립토 차르 “美 정부 비트코인 추가 매입 검토…부채...   \n",
       "1   1            [비즈 나우] 비트코인 2025 컨퍼런스 개막…'전략자산' 선언 코앞    \n",
       "2   2    “맥O날드보다 맛없어!” 혹평이 가득한 트럼프 만찬과 비트코인 피자데이[엠블록레터]    \n",
       "3   3         블랙록, 자사 비트코인 ETF 보유량 25% 확대…기관 투자 본격화 신호탄    \n",
       "4   4                비트코인, 트럼프 미디어 비축 소식에도 주춤…1억5100만원대    \n",
       "5   5                 '비트코인 빚투' 스트레티지, 또 샀다…보유량 58만개 돌파    \n",
       "6   6                        美 상원의원 \"트럼프 대통령, 비트코인법 지지\"    \n",
       "7   7                       숨 고르는 비트코인, 10만8000달러선 '주춤'    \n",
       "8   8   [비트코인 2025] 로빈후드 창업자 “토큰화 증권은 美 ‘자본 패권’ 키우는 수단”    \n",
       "9   9           트럼프미디어그룹, 25억 달러 규모 자금 조달 통해 비트코인 매입 예고    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20250528103907230  \n",
       "1  http://v.daum.net/v/20250528075215864  \n",
       "2  http://v.daum.net/v/20250528143002735  \n",
       "3  http://v.daum.net/v/20250528151802080  \n",
       "4  http://v.daum.net/v/20250528095112897  \n",
       "5  http://v.daum.net/v/20250528042404292  \n",
       "6  http://v.daum.net/v/20250528090342853  \n",
       "7  http://v.daum.net/v/20250528095921258  \n",
       "8  http://v.daum.net/v/20250528110600761  \n",
       "9  http://v.daum.net/v/20250528084245020  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "word = '비트코인'\n",
    "\n",
    "url = \"https://search.daum.net/search?w=news&nil_search=btn&DA=NTB&enc=utf8&cluster=y&cluster_page=1&q=\"+word\n",
    "\n",
    "response = requests.get(url)\n",
    "response, response.status_code\n",
    "\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "items_find_list = [] # 검색한 결과를 담는 2차원 리스트\n",
    "\n",
    "item_el = soup.select('div.item-title > strong.tit-g.clamp-g > a')\n",
    "\n",
    "for idx, item in enumerate(item_el):\n",
    "    items_find_list.append([idx, item.text, item.attrs.get('href')])\n",
    "\n",
    "pd.DataFrame(items_find_list,columns=['no','title','link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e134bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 10, 'title': ' 트럼프미디어그룹, 25억 달러 규모 자금 조달 통해 비트코인 매입 예고 ', 'link': 'http://v.daum.net/v/20250528084245020'}\n",
      "{'no': 11, 'title': ' 연일 최고가 경신하는 비트코인…투자자들 강 건너 불구경하는 이유는 ', 'link': 'http://v.daum.net/v/20250526212400275'}\n",
      "{'no': 12, 'title': ' \"비트코인 산다\"…트럼프家, 25억달러 자금 조달 추진[코인브리핑] ', 'link': 'http://v.daum.net/v/20250528111837527'}\n",
      "{'no': 13, 'title': ' [김대호 박사의 오늘의 키워드] 소비자신뢰지수·비트코인 2025·머스크 한마디·애플 괘씸죄 ', 'link': 'http://v.daum.net/v/20250528071325361'}\n",
      "{'no': 14, 'title': ' 잘 나가는 비트코인 산다는데 왜?…트럼프 미디어 주가 10% 급락 [투자360] ', 'link': 'http://v.daum.net/v/20250528074002668'}\n",
      "{'no': 15, 'title': ' \"테슬라 팔고 갈아탔어요\"…자녀계좌 보던 엄마들 \\'돌변\\' [마켓PRO] ', 'link': 'http://v.daum.net/v/20250528094602647'}\n",
      "{'no': 16, 'title': ' 스트래티지, 비트코인 4020개 추가 매입...보유량 58만개 돌파 ', 'link': 'http://v.daum.net/v/20250527081116129'}\n",
      "{'no': 17, 'title': ' 달러 스테이블코인, 국내 거래 확산…당국 외환흐름 통제력 약화 우려 ', 'link': 'http://v.daum.net/v/20250528152520516'}\n",
      "{'no': 18, 'title': ' 비트코인과 엇갈리는 이더리움·리플, 왜? ', 'link': 'http://v.daum.net/v/20250526164319028'}\n",
      "{'no': 19, 'title': ' [영상] “강세장 진입한 비트코인, 내년 2분기까지 최소 20만~30만 달러 갈 듯” ', 'link': 'http://v.daum.net/v/20250527090137566'}\n"
     ]
    }
   ],
   "source": [
    "# 다음 뉴스 검색(키워드, 원하는 페이ㅣ)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "keyword = '비트코인'\n",
    "page = 2\n",
    "\n",
    "# url = f\"https://search.daum.net/search?w=news&nil_search=btn&DA=NTB&enc=utf8&cluster=y&q={keyword}&p={page}\"\n",
    "# print(url)\n",
    "# response = requests.get(url)\n",
    "\n",
    "url = f\"https://search.daum.net/search?w=news&nil_search=btn&DA=NTB&enc=utf8&cluster=y\"\n",
    "params = {'q':keyword,'p':page}\n",
    "response = requests.get(url, params=params)\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "items_find_list = [] # 검색한 결과를 담는 2차원 리스트\n",
    "item_el = soup.select('div.item-title > strong.tit-g.clamp-g > a')\n",
    "\n",
    "for idx, item in enumerate(item_el):\n",
    "    items_find_list.append({'no': (page-1)*10+idx, 'title':item.text, 'link':item.attrs.get('href')})\n",
    "    print({'no': (page-1)*10+idx, 'title':item.text, 'link':item.attrs.get('href')})\n",
    "    \n",
    "# pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29a1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'no': 20,\n",
       "  'title': ' <단독>\"예배 참석하면 코인 드려요. 5년 안에 비트코인 넘어섭니다\"..신앙심 노린 코인 유사 사기 기승 ',\n",
       "  'link': 'http://v.daum.net/v/20250528083323774'},\n",
       " {'no': 21,\n",
       "  'title': ' 트럼프미디어, 비트코인 3.4조 투자 발표에 주가 10% 폭락 ',\n",
       "  'link': 'http://v.daum.net/v/20250528080206055'},\n",
       " {'no': 22,\n",
       "  'title': ' “가상화폐=애완용 돌” 직격했던 ‘월가황제’ 돌변…美 1위 은행도 주목한 ‘이것’ [월가그루픽] ',\n",
       "  'link': 'http://v.daum.net/v/20250528153835219'},\n",
       " {'no': 23,\n",
       "  'title': ' 비트레이어, 비트코인 채굴업체와 협력...“BTC 디파이로 나아갈 것” ',\n",
       "  'link': 'http://v.daum.net/v/20250527114126672'},\n",
       " {'no': 24,\n",
       "  'title': ' 뉴욕증시 휴장에 10.9만弗선 숨고른 비트코인 [매일코인] ',\n",
       "  'link': 'http://v.daum.net/v/20250527103810840'},\n",
       " {'no': 25,\n",
       "  'title': ' 스트래티지, 비트코인 4020개 추가 매입...보유량 58만개 돌파 ',\n",
       "  'link': 'http://v.daum.net/v/20250527081116129'},\n",
       " {'no': 26,\n",
       "  'title': ' \"죽고 싶지 않으면 비트코인 비번 내놔\"···외국인 납치·고문한 \\'가상자산 왕\\' ',\n",
       "  'link': 'http://v.daum.net/v/20250528060036428'},\n",
       " {'no': 27,\n",
       "  'title': ' [영상] “강세장 진입한 비트코인, 내년 2분기까지 최소 20만~30만 달러 갈 듯” ',\n",
       "  'link': 'http://v.daum.net/v/20250527090137566'},\n",
       " {'no': 28,\n",
       "  'title': ' 美 트럼프 대통령, EU 관세 연기…비트코인, 1.67% 상승 ',\n",
       "  'link': 'http://v.daum.net/v/20250527072542319'},\n",
       " {'no': 29,\n",
       "  'title': ' \"비트코인, 해킹에 안전한 시간 20년 남아…완벽한 양자컴에 뚫려\" ',\n",
       "  'link': 'http://v.daum.net/v/20250527084812094'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def collect_list(keyword, page=1):\n",
    "    'keyword로 다음 검색한 결과(해당 page)를 return'\n",
    "    url = f\"https://search.daum.net/search?w=news&nil_search=btn&DA=NTB&enc=utf8&cluster=y\"\n",
    "    params = {'q':keyword,'p':page}\n",
    "    response = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "    items_find_list = [] # 검색한 결과를 담는 2차원 리스트\n",
    "    item_el = soup.select('div.item-title > strong.tit-g.clamp-g > a')\n",
    "\n",
    "    for idx, item in enumerate(item_el):\n",
    "        items_find_list.append({'no': (page-1)*10+idx, 'title':item.text, 'link':item.attrs.get('href')})\n",
    "\n",
    "    return items_find_list\n",
    "\n",
    "collect_list('비트코인',3)    \n",
    "    \n",
    "# pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "013350cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[단독]대선 투표도 거르고 ‘외유성 출장’···대구지역 노사 대표들 해외 방문 논란</td>\n",
       "      <td>http://v.daum.net/v/20250527060110255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[팩트체크] 세로쓰기에서 가로쓰기까지…대선 투표용지 변천사</td>\n",
       "      <td>http://v.daum.net/v/20250528065513098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>“대선 투표 꼭…” 한국교회, 캠페인·기도회로 독려</td>\n",
       "      <td>http://v.daum.net/v/20250528030315081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>우범기 전주시장, 대선 투표 독려 캠페인 동참</td>\n",
       "      <td>http://v.daum.net/v/20250528110014351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"근로자 대선 투표 보장\"…광주상의·경총·TP, 실천 캠페인(종합)</td>\n",
       "      <td>http://v.daum.net/v/20250527173934357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                             title  \\\n",
       "0   0   [단독]대선 투표도 거르고 ‘외유성 출장’···대구지역 노사 대표들 해외 방문 논란    \n",
       "1   1                 [팩트체크] 세로쓰기에서 가로쓰기까지…대선 투표용지 변천사    \n",
       "2   2                     “대선 투표 꼭…” 한국교회, 캠페인·기도회로 독려    \n",
       "3   3                        우범기 전주시장, 대선 투표 독려 캠페인 동참    \n",
       "4   4            \"근로자 대선 투표 보장\"…광주상의·경총·TP, 실천 캠페인(종합)    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20250527060110255  \n",
       "1  http://v.daum.net/v/20250528065513098  \n",
       "2  http://v.daum.net/v/20250528030315081  \n",
       "3  http://v.daum.net/v/20250528110014351  \n",
       "4  http://v.daum.net/v/20250527173934357  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원하는 keyword 다음검색\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "result = []\n",
    "keyword = \"청바지\"\n",
    "pages = 3\n",
    "\n",
    "for page in range(1, pages+1):\n",
    "    result.extend(collect_list(keyword, page))\n",
    "    time.sleep(3)\n",
    "    \n",
    "result_pd = pd.DataFrame(result)\n",
    "result_pd\n",
    "result_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ca45673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~0번째 청바지 5 검색 중입니다.~~~\n",
      "0 청바지 1\n",
      "0 청바지 2\n",
      "0 청바지 3\n",
      "0 청바지 4\n",
      "0 청바지 5\n",
      "~~~1번째 면바지 5 검색 중입니다.~~~\n",
      "1 면바지 1\n",
      "1 면바지 2\n",
      "1 면바지 3\n",
      "1 면바지 4\n",
      "1 면바지 5\n"
     ]
    }
   ],
   "source": [
    "keywords = ['청바지','면바지']\n",
    "pages = 5\n",
    "result0 = [] # 청바지 검색결과 50개\n",
    "result1 = [] # 면바지 검색결과 50개\n",
    "\n",
    "for i, keyword in enumerate(keywords):\n",
    "    print(f'~~~{i}번째 {keyword} {page} 검색 중입니다.~~~')\n",
    "    for page in range(1, pages+1):\n",
    "        print(i, keyword, page)\n",
    "        if i == 0:\n",
    "            result0.extend(collect_list(keyword, page))\n",
    "        else :\n",
    "            result1.extend(collect_list(keyword, page))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d1029d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>아이브 가을 ‘청바지핏 뽐내는 시구’ [MK포토]</td>\n",
       "      <td>http://v.daum.net/v/20250527184503588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>'윤남기♥' 이다은, 다이어트 21kg 감량 효과 있네···완벽한 청바지 자태</td>\n",
       "      <td>http://v.daum.net/v/20250427195408997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>손담비, 출산 25일 만에 외출…붓기 없이 청바지 ‘완벽핏’ [MD★스타]</td>\n",
       "      <td>http://v.daum.net/v/20250506155104793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>하이키 옐, ‘톡식’ 커버 영상 화제…흰 티+청바지로도 ‘핫해’</td>\n",
       "      <td>http://v.daum.net/v/20250430145626938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>효민, 신행 다녀와서 ♥S대 금융맨家 찾았나? 흰티+청바지 청순룩 컴백</td>\n",
       "      <td>http://v.daum.net/v/20250430135410662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                          title  \\\n",
       "0  30                   아이브 가을 ‘청바지핏 뽐내는 시구’ [MK포토]    \n",
       "1  31   '윤남기♥' 이다은, 다이어트 21kg 감량 효과 있네···완벽한 청바지 자태    \n",
       "2  32     손담비, 출산 25일 만에 외출…붓기 없이 청바지 ‘완벽핏’ [MD★스타]    \n",
       "3  33           하이키 옐, ‘톡식’ 커버 영상 화제…흰 티+청바지로도 ‘핫해’    \n",
       "4  34       효민, 신행 다녀와서 ♥S대 금융맨家 찾았나? 흰티+청바지 청순룩 컴백    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20250527184503588  \n",
       "1  http://v.daum.net/v/20250427195408997  \n",
       "2  http://v.daum.net/v/20250506155104793  \n",
       "3  http://v.daum.net/v/20250430145626938  \n",
       "4  http://v.daum.net/v/20250430135410662  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0_df = pd.DataFrame(result0)\n",
    "result0_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4999f08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>사천에서 쾌청한 날씨 속 탁 트인 남해 풍경 즐겨요!</td>\n",
       "      <td>http://v.daum.net/v/20250528104429529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>윤승아, ♥김무열 쏙 빼닮은 깜찍 子 하객룩 공개‥벌써 우월한 유전자</td>\n",
       "      <td>http://v.daum.net/v/20250526145941690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이번 주 포천 여행,반팔 하나로 충분할까?</td>\n",
       "      <td>http://v.daum.net/v/20250527171732518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이재명, 첫 대학 방문…이준석 겨냥?</td>\n",
       "      <td>http://v.daum.net/v/20250526191942751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"나는 젊어\" 팔소매 접은 이준석의 '흰셔츠' 속에도 뼈가 담겼다[21대 대선 리...</td>\n",
       "      <td>http://v.daum.net/v/20250525070013619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   0                     사천에서 쾌청한 날씨 속 탁 트인 남해 풍경 즐겨요!    \n",
       "1   1            윤승아, ♥김무열 쏙 빼닮은 깜찍 子 하객룩 공개‥벌써 우월한 유전자    \n",
       "2   2                           이번 주 포천 여행,반팔 하나로 충분할까?    \n",
       "3   3                              이재명, 첫 대학 방문…이준석 겨냥?    \n",
       "4   4   \"나는 젊어\" 팔소매 접은 이준석의 '흰셔츠' 속에도 뼈가 담겼다[21대 대선 리...   \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20250528104429529  \n",
       "1  http://v.daum.net/v/20250526145941690  \n",
       "2  http://v.daum.net/v/20250527171732518  \n",
       "3  http://v.daum.net/v/20250526191942751  \n",
       "4  http://v.daum.net/v/20250525070013619  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1_df = pd.DataFrame(result1)\n",
    "result1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51ef0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "result0_df.to_csv('data/ch14_'+keywords[0]+'.csv', index=False, encoding='cp949')\n",
    "result1_df.to_csv('data/ch14_'+keywords[1]+'.csv', index=False) # utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5eec8",
   "metadata": {},
   "source": [
    "### 4) user-agent 를 추가하여 크롤링\n",
    "\n",
    "- urlopen() 함수를 사용하면 크롤링이 안 되는 사이트\n",
    "- User-agent 를 추가하여 크롤링 ex) Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\n",
    "\n",
    "#### ★ url에 한글이 있을 경우 : urllib.parse.quote(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac9c8db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'no': 20,\n",
       "  'title': ' 백종원 빽다방, 내달 12일까지 음료 할인…비용 본사가 부담 ',\n",
       "  'link': 'http://v.daum.net/v/20250527082714508'},\n",
       " {'no': 21,\n",
       "  'title': ' K푸드 수출, 이젠 소스다…불닭 넘는 다음 한 수는 ',\n",
       "  'link': 'http://v.daum.net/v/20250528140952873'},\n",
       " {'no': 22,\n",
       "  'title': ' 쏟아지는 악재 악재...매출 45% 급감 끝없는 ‘백종원 리스크’ ',\n",
       "  'link': 'http://v.daum.net/v/20250526113905209'},\n",
       " {'no': 23,\n",
       "  'title': ' \"백종원 대놓고 사기 쳐\" 연이은 악재에 또...가맹점 매출 \\'급감\\' [지금이뉴스] ',\n",
       "  'link': 'http://v.daum.net/v/20250526111905124'},\n",
       " {'no': 24,\n",
       "  'title': ' 백종원 빽다방, 릴레이 할인 진행…\"가맹점 부담 NO\" ',\n",
       "  'link': 'http://v.daum.net/v/20250527081520232'},\n",
       " {'no': 25,\n",
       "  'title': ' 빽다방, 할인 행사…\"본사가 비용 전액 부담해 가맹점 매출 증대\" ',\n",
       "  'link': 'http://v.daum.net/v/20250527090303655'},\n",
       " {'no': 26,\n",
       "  'title': ' 빽다방, 아메리카노 500원에 판다…할인 프로모션 내달 12일까지 ',\n",
       "  'link': 'http://v.daum.net/v/20250527185546889'},\n",
       " {'no': 27,\n",
       "  'title': \" 백종원 리스크에 가맹점주들 '직격타'…매출 20% 급감 \",\n",
       "  'link': 'http://v.daum.net/v/20250526090415260'},\n",
       " {'no': 28,\n",
       "  'title': ' \"아아 500원, 라떼 1000원\" 빽다방 릴레이 할인 ',\n",
       "  'link': 'http://v.daum.net/v/20250527160152665'},\n",
       " {'no': 29,\n",
       "  'title': ' 빽다방 \"아메리카노 500원\" 파격행사…비용은 본사 부담 ',\n",
       "  'link': 'http://v.daum.net/v/20250527115751260'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# url에 한글이 있을 경우 import\n",
    "import urllib.parse\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "word = '비트코인'\n",
    "word = urllib.parse.quote(word)\n",
    "\n",
    "url = \"https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=\"+word+\"&p=2\"\n",
    "# print(url)\n",
    "\n",
    "# User-Agent 를 추가하여, 브라우저처험 보이게 포장\n",
    "headers = {'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36'}\n",
    "\n",
    "request = Request(url, headers=headers)\n",
    "response = urlopen(request)\n",
    "response.status\n",
    "\n",
    "soup = BeautifulSoup(response.read(),'html.parser')\n",
    "\n",
    "def collect_list(keyword, page=1):\n",
    "    'keyword로 다음 검색한 결과(해당 page)를 return'\n",
    "    url = f\"https://search.daum.net/search?w=news&nil_search=btn&DA=NTB&enc=utf8&cluster=y\"\n",
    "    params = {'q':keyword,'p':page}\n",
    "    response = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "    items_find_list = [] # 검색한 결과를 담는 2차원 리스트\n",
    "    item_el = soup.select('div.item-title > strong.tit-g.clamp-g > a')\n",
    "\n",
    "    for idx, item in enumerate(item_el):\n",
    "        items_find_list.append({'no': (page-1)*10+idx, 'title':item.text, 'link':item.attrs.get('href')})\n",
    "\n",
    "    return items_find_list\n",
    "\n",
    "\n",
    "collect_list('백종원',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4ce86",
   "metadata": {},
   "source": [
    "- ★ 꼭 User-Agent를 사용하여햐 하는 경우 : https://www.melon.com/chart/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ffa613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "\n",
    "melon_page = requests.get(url)\n",
    "melon_page.status_code # 406 페이지가 막혀있는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d7179480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "\n",
    "# melon_page = urlopen(url) # 에러남\n",
    "# melon_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9942c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-agent 추가\n",
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "headers = {\"user-agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\"}\n",
    "\n",
    "# 방법2\n",
    "# request = Request(url, headers=headers)\n",
    "# melon_page = urlopen(request)\n",
    "# melon_page.status\n",
    "\n",
    "# soup = BeautifulSoup(melon_page,'html.parser')\n",
    "\n",
    "# 방법1\n",
    "melon_page = requests.get(url, headers=headers)\n",
    "melon_page.status_code\n",
    "\n",
    "soup = BeautifulSoup(melon_page.text,'html.parser')\n",
    "# soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ebcbcc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>멜론순위</th>\n",
       "      <th>노래제목</th>\n",
       "      <th>가수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Never Ending Story</td>\n",
       "      <td>아이유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>너에게 닿기를</td>\n",
       "      <td>10CM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Drowning</td>\n",
       "      <td>WOODZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>네모의 꿈</td>\n",
       "      <td>아이유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>like JENNIE</td>\n",
       "      <td>제니 (JENNIE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>모르시나요(PROD.로코베리)</td>\n",
       "      <td>조째즈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>THUNDER</td>\n",
       "      <td>세븐틴 (SEVENTEEN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>TOO BAD (feat. Anderson .Paak)</td>\n",
       "      <td>G-DRAGON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>aespa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>어제보다 슬픈 오늘</td>\n",
       "      <td>우디 (Woody)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>나는 반딧불</td>\n",
       "      <td>황가람</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>빨간 운동화</td>\n",
       "      <td>아이유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>HOME SWEET HOME (feat. 태양, 대성)</td>\n",
       "      <td>G-DRAGON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>오늘만 I LOVE YOU</td>\n",
       "      <td>BOYNEXTDOOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Flower</td>\n",
       "      <td>오반(OVAN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>REBEL HEART</td>\n",
       "      <td>IVE (아이브)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>DAY6 (데이식스)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>10월 4일</td>\n",
       "      <td>아이유</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    멜론순위                            노래제목               가수\n",
       "0      1              Never Ending Story              아이유\n",
       "1      2                         너에게 닿기를             10CM\n",
       "2      3                        Drowning            WOODZ\n",
       "3      4                           네모의 꿈              아이유\n",
       "4      5                     like JENNIE      제니 (JENNIE)\n",
       "5      6                모르시나요(PROD.로코베리)              조째즈\n",
       "6      7                         THUNDER  세븐틴 (SEVENTEEN)\n",
       "7      8  TOO BAD (feat. Anderson .Paak)         G-DRAGON\n",
       "8      9                        Whiplash            aespa\n",
       "9     10                      어제보다 슬픈 오늘       우디 (Woody)\n",
       "10    11                          나는 반딧불              황가람\n",
       "11    12                          빨간 운동화              아이유\n",
       "12    13  HOME SWEET HOME (feat. 태양, 대성)         G-DRAGON\n",
       "13    14                  오늘만 I LOVE YOU      BOYNEXTDOOR\n",
       "14    15                          Flower         오반(OVAN)\n",
       "15    16                     REBEL HEART        IVE (아이브)\n",
       "16    17                           HAPPY      DAY6 (데이식스)\n",
       "17    18                          10월 4일              아이유"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 멜론 순위  노래제목,       가수  \n",
    "# 1위        너에게 달기를   10cm  \n",
    "\n",
    "title = soup.select('table div.ellipsis > span:nth-child(1) > a')\n",
    "\n",
    "# [t.text.strip() for t in title]\n",
    "\n",
    "writer = soup.select('table div.ellipsis > span.checkEllipsis')\n",
    "# [w.text for w in write]\n",
    "\n",
    "\n",
    "result = []\n",
    "\n",
    "# for idx, t in enumerate(title):\n",
    "#     print(f'{idx}')\n",
    "#     result.append({'멜론순위': idx+1,\"노래제목\":title[idx].text, \"가수\":writer[idx].text})\n",
    "# #     time.sleep(1)\n",
    "\n",
    "for idx, (t, w) in enumerate(zip(title, writer)):\n",
    "    result.append({\n",
    "        '멜론순위':idx+1, \"노래제목\":t.text, \"가수\":w.text\n",
    "    })\n",
    "# result\n",
    "melongData = pd.DataFrame(result)\n",
    "melongData.head(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af081b2",
   "metadata": {},
   "source": [
    "### 5) 네이버 지식인으로 검색 (open API 사용 없이) \n",
    "\n",
    "- 특정 keyword를 특정페이지 수(3) 만큰 검색한 결과 데이터프레임으로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dcd6cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "keyword = '쳇지피티'\n",
    "url= \"https://kin.naver.com/search/list.naver?query={}\".format(keyword)\n",
    "# print(url)\n",
    "response = get(url)\n",
    "response.status_code\n",
    "\n",
    "soup = BeautifulSoup(response.content,'html.parser') # response.content == response.text\n",
    "# soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "47da900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kin.naver.com/search/list.naver?query=%EC%B3%87%EC%A7%80%ED%94%BC%ED%8B%B0\n"
     ]
    }
   ],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "\n",
    "# 챗지피티 -> %EC%B1%97%EC%A7%80%ED%94%BC%ED%8B%B0\n",
    "keyword = '쳇지피티'\n",
    "keyword = quote(keyword) # url 인코딩된 문자열 전환\n",
    "\n",
    "url= \"https://kin.naver.com/search/list.naver?query={}\".format(keyword)\n",
    "print(url)\n",
    "\n",
    "response = urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(response,'html.parser') # response == response.read()\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a285ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이징 포함 (keyword를 pages수 만큼 검색한 결과를 데이터프레임에 )\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "keyword = '쳇지피티'\n",
    "pages = 3\n",
    "item_list = [] # 크롤링 한 데이터를 담을 list(2차원 리스트)\n",
    "\n",
    "for page in range(1, pages+1):\n",
    "    # print(page)\n",
    "\n",
    "    url= f'https://kin.naver.com/search/list.naver?query={keyword}&page={page}'\n",
    "    # print(url)\n",
    "    response = get(url)\n",
    "    # print(response.status_code)\n",
    "\n",
    "    soup = BeautifulSoup(response.text,'html.parser') # response.content == response.text\n",
    "    # print(soup)\n",
    "        \n",
    "    # items= soup.select('ul.basic1 >li a._searchListTitleAnchor')\n",
    "    items= soup.select('dt > a')\n",
    "    \n",
    "    # print([item.text for item in items]) # title\n",
    "    # print([item.attrs.get('href') for item in items]) # link\n",
    "    \n",
    "    for item in items:\n",
    "        item_list.append([item.text, item.attrs.get('href')])\n",
    "        # item_list_append({'title': item.text,'link': item.attrs.get('hred'),})\n",
    "    \n",
    "# print(len(item_list),'개 데이터')\n",
    "# print(item_list[:2])\n",
    "df = pd.DataFrame(item_list, columns=['title','link'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6182af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all()\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "keyword = '쳇지피티'\n",
    "pages = 3\n",
    "item_list = [] # 크롤링 한 데이터를 담을 list(2차원 리스트)\n",
    "\n",
    "for page in range(1, pages+1):\n",
    "    # print(page)\n",
    "\n",
    "    url= f'https://kin.naver.com/search/list.naver?query={keyword}&page={page}'\n",
    "\n",
    "    response = get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text,'html.parser') # response.content == response.text\n",
    "        \n",
    "    dts= soup.find_all('dt')\n",
    "    \n",
    "    for dt in dts:\n",
    "        item = dt.find('a')\n",
    "        \n",
    "        item_list.append([item.text, item.attrs.get('href')])\n",
    "\n",
    "df = pd.DataFrame(item_list, columns=['title','link'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6bcbc8",
   "metadata": {},
   "source": [
    "#### ★ 함수 (keyword를 pages수 만큼 검색한 결과를 데이터프레임에 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "00e419e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 (keyword를 pages수 만큼 검색한 결과를 데이터프레임에 )\n",
    "def get_items_list(keyword, pages=1):\n",
    "    from requests import get\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "\n",
    "    item_list = []  # 크롤링 한 데이터를 담을 list(2차원 리스트)\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        # print(page)\n",
    "\n",
    "        url = f'https://kin.naver.com/search/list.naver?query={keyword}&page={page}'\n",
    "\n",
    "        response = get(url)\n",
    "\n",
    "        soup = BeautifulSoup(\n",
    "            response.text, 'html.parser')  # response.content == response.text\n",
    "\n",
    "        dts = soup.find_all('dt')\n",
    "\n",
    "        for dt in dts:\n",
    "            item = dt.find('a')\n",
    "\n",
    "            item_list.append([item.text, item.attrs.get('href')])\n",
    "\n",
    "    return pd.DataFrame(item_list, columns=['title', 'link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ff1ba68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>영어로 청바지를 뭐라고하나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전 남자인데, 누워서 청바지를 입으면...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=7&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>청바지 없는데 면접취소 할까요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>고관절 지방이식 후 청바지</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=7&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임영웅 청바지 입은 사진?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>청바지 세탁</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>미국에서 청바지 가격이 306불입니다...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=4&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>청바지? 면바지도 트레이닝바지인가요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>핀턱 청바지 수선</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>청바지 이염</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>골프 연습장 에서 부츠컷 청바지 입어도...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>강아지 청바지 뜯어먹음</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>청바지 수선</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>청바지는 오랫동안 쓸 수 있나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>여자들중에 원피스보다 청바지가 예쁜...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>체육대회때 흰티에 청바지 입어도 되나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8월 초 이탈리아 청바지</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>청바지는 오랫동안 쓸 수 있나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>청바지에서 파란 물</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40대 남자도 청바지를 입나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>검은 청바지에 검은 티셔츠 ㄱㅊ나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>청바지 이름이 뭔가요..??</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>청바지 수선이요</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>남자가 청바지를 입으면 고환이 아플 수...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=7&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>청바지 섬유유연제 넣어도 빳빳해요</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>임영웅 청바지 입은 사진?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>런닝맨 옛날꺼에 송지효가 청바지만 입은...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>회색후드티 청바지 레이어드 없어도...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>청바지 자국 남은거 지울수 없나요??</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>와이드 청바지 빨래</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  \\\n",
       "0            영어로 청바지를 뭐라고하나요?   \n",
       "1    전 남자인데, 누워서 청바지를 입으면...    \n",
       "2           청바지 없는데 면접취소 할까요?   \n",
       "3              고관절 지방이식 후 청바지   \n",
       "4              임영웅 청바지 입은 사진?   \n",
       "5                      청바지 세탁   \n",
       "6    미국에서 청바지 가격이 306불입니다...    \n",
       "7        청바지? 면바지도 트레이닝바지인가요?   \n",
       "8                   핀턱 청바지 수선   \n",
       "9                      청바지 이염   \n",
       "10  골프 연습장 에서 부츠컷 청바지 입어도...    \n",
       "11               강아지 청바지 뜯어먹음   \n",
       "12                     청바지 수선   \n",
       "13         청바지는 오랫동안 쓸 수 있나요?   \n",
       "14    여자들중에 원피스보다 청바지가 예쁜...    \n",
       "15     체육대회때 흰티에 청바지 입어도 되나요?   \n",
       "16              8월 초 이탈리아 청바지   \n",
       "17         청바지는 오랫동안 쓸 수 있나요?   \n",
       "18                 청바지에서 파란 물   \n",
       "19          40대 남자도 청바지를 입나요?   \n",
       "20       검은 청바지에 검은 티셔츠 ㄱㅊ나요?   \n",
       "21            청바지 이름이 뭔가요..??   \n",
       "22                   청바지 수선이요   \n",
       "23  남자가 청바지를 입으면 고환이 아플 수...    \n",
       "24         청바지 섬유유연제 넣어도 빳빳해요   \n",
       "25             임영웅 청바지 입은 사진?   \n",
       "26  런닝맨 옛날꺼에 송지효가 청바지만 입은...    \n",
       "27     회색후드티 청바지 레이어드 없어도...    \n",
       "28       청바지 자국 남은거 지울수 없나요??   \n",
       "29                 와이드 청바지 빨래   \n",
       "\n",
       "                                                 link  \n",
       "0   https://kin.naver.com/qna/detail.naver?d1id=11...  \n",
       "1   https://kin.naver.com/qna/detail.naver?d1id=7&...  \n",
       "2   https://kin.naver.com/qna/detail.naver?d1id=6&...  \n",
       "3   https://kin.naver.com/qna/detail.naver?d1id=7&...  \n",
       "4   https://kin.naver.com/qna/detail.naver?d1id=3&...  \n",
       "5   https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "6   https://kin.naver.com/qna/detail.naver?d1id=4&...  \n",
       "7   https://kin.naver.com/qna/detail.naver?d1id=13...  \n",
       "8   https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "9   https://kin.naver.com/qna/detail.naver?d1id=5&...  \n",
       "10  https://kin.naver.com/qna/detail.naver?d1id=10...  \n",
       "11  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "12  https://kin.naver.com/qna/detail.naver?d1id=5&...  \n",
       "13  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "14  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "15  https://kin.naver.com/qna/detail.naver?d1id=5&...  \n",
       "16  https://kin.naver.com/qna/detail.naver?d1id=9&...  \n",
       "17  https://kin.naver.com/qna/detail.naver?d1id=5&...  \n",
       "18  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "19  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "20  https://kin.naver.com/qna/detail.naver?d1id=5&...  \n",
       "21  https://kin.naver.com/qna/detail.naver?d1id=5&...  \n",
       "22  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "23  https://kin.naver.com/qna/detail.naver?d1id=7&...  \n",
       "24  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "25  https://kin.naver.com/qna/detail.naver?d1id=3&...  \n",
       "26  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "27  https://kin.naver.com/qna/detail.naver?d1id=8&...  \n",
       "28  https://kin.naver.com/qna/detail.naver?d1id=5&...  \n",
       "29  https://kin.naver.com/qna/detail.naver?d1id=10...  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_list('청바지', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92e868",
   "metadata": {},
   "source": [
    "### 6) 네이버 지식인으로 검색 (open API 사용)\n",
    "\n",
    "- 특정 keyword를 특정데이터 수(30) 만큼 검색한 결과 데이터프레임으로 출력\n",
    "    #### ★ pip install python-dotenv\n",
    "    - .env에 발급받은 키 저장 → load (pip install python-dotenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ccd81626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수를 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # 기본 : dotenv_path='.env' → 실행시 True\n",
    "# print(os.getenv('Client_ID'))\n",
    "# print(os.getenv('Client_Secret'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e818da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '<b>쳇지피티</b> 논문 출처', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=4&dirId=40608&docId=471249146&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '<b>쳇지피티</b>한테 어떤 내용에 관한 논문을 요구하고, 해당... 지피티가 스스로 여러 논문을 합쳐서 저에게 정보를 제공해준 건가요? 안녕하세요 <b>쳇지피티</b>가 작성한 글은 내용을... 그러니 전적으로 <b>쳇지피티</b>를 의지 하지 말라고 말씀드리고... '}, {'title': '<b>쳇지피티</b> 한도', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=1&dirId=1060101&docId=484917198&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '<b>쳇지피티</b> 무료로 쓰고 있는데 <b>쳇지피티</b>로 소설 하나 쓰고 있거든요 근데 한도가 초과됐다고 5시간 뒤에 다시 사용하라는데.. 5시간 뒤에 다시 이어서 쓸 수 있나요? 아니면 이미 한도 초과되서 다시 이어서 쓰는게 아예 안 되나요 5시간... '}, {'title': '<b>쳇지피티</b> 사용 확인 AI', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=5&dirId=50404&docId=483106243&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '<b>쳇지피티</b> 사용 여부 확인하는 무료 AI 뭐가 있나요?? 좀 정확하고 확실한거로 알려주세요 현재 대부분의 AI 탐색기는 영어 콘텐츠 중심으로 설계되어 있어, 한글은 정확하게 판별되지 않거나 결과 신뢰도가 낮습니다. GPTZero... '}, {'title': '<b>쳇지피티</b> 이거 뭐예요?해킹 뭐그런거 당하는거 아니죠?', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=1&dirId=11001&docId=476675623&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '아니 제가 크롬을 쓰는데 자꾸 <b>쳇지피티</b>가 한글번역도 이상하게 되고 말도 끊기는 거예요ㅜ 그래서 제가 너 자구 오류뜬다고! 라고 보냈더니 너 자구 어쩌지 지구 어쩌구 이렇게 지혼자서 번역이 되더니 갑자기 저렇게 떴어요ㅜㅜㅜ 막... '}, {'title': '<b>쳇지피티</b> ai 소라 질문이요', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=485632823&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': \"<b>쳇지피티</b> 플러스 이용중이구요 어제까지만 해도 왼쪽 메뉴에 '소라' 가 있어서요 해서 이미지제작을 했었는데 오늘 메뉴에 있던 '소라'가 없어졌어요 고객센터연락방법도 모르고 해서 혹시 정확히 아시는 분 계시면 답글 좀 부탁드릴께요... \"}, {'title': '<b>쳇지피티</b> 초기화', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10601&docId=482630888&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': \"<b>쳇지피티</b> 대화 목록이 사라진건 아니고 맥락에 안 맞게 말하길래 한도 초과... 챗 지피티 사용 중에 당황스러우셨겠어요. 챗 지피티의 무료 버전은 일정... 유료 구독 전환: '챗 지피티 플러스'는 월 20달러의 구독료로 더 많은... \"}, {'title': '학교 생기부 <b>쳇지피티</b>', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=4&dirId=40602&docId=485473882&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '학교에서 생기부를 작성할 때 <b>쳇지피티</b>를 그대로 배낀 보고서를 내면 대학에서 잡는다는데 세특은 선생님이 적어주시는건데 어떻게 그대로 베낀 것을 찾아내나요? 그리고 걸리면 어떤 불이익이 발생하나요? 대학에서는 세특 내용... '}, {'title': '제가 직접 쓴 자소서 <b>쳇지피티</b>', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=4&dirId=406&docId=478038913&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '제가 직접 제 이야기로 자소서를 쓰고 <b>쳇지피티</b>한테 보내고 지피티가 수정해준 내용 참고용으로 보고, 괜찮은 부분은... <b>쳇지피티</b> 돌리면..... 제가 쓴 문맥이 그대로인 부분도 있어서 그냥 복붙하게 되는 항목도 생기는데ㅠ <b>쳇지피티</b>... '}, {'title': '<b>쳇지피티</b> 질문입니다.', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=1&dirId=113&docId=484002935&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '요즘 <b>쳇지피티</b>가 유행이길래 한번 깔아봤는데 인사조차 못알아먹는데 어떻게 하나요..? 안녕하세요. 바로재생 IT... 질문 요즘 <b>쳇지피티</b>가 유행이길래 한번 깔아봤는데 인사조차 못알아먹는데 어떻게 하나요..? 답변 네트워크... '}, {'title': '<b>쳇지피티</b> 채팅 문제', 'link': 'https://kin.naver.com/qna/detail.naver?d1id=1&dirId=102&docId=483058690&qb=7LOH7KeA7ZS87Yuw&enc=utf8', 'description': '<b>쳇지피티</b>3.0 무료버전을 종종 사용합니다 제가 질문을 &quot;이번에 전시회를 할꺼야&quot; 라고 채팅을 치면 채팅창... 그리고 <b>쳇지피티</b> 답변도 말하다 마는듯하게 하고 어문도 굉장히 이상하게 말합니다 그런데 그 말을 복사해서 다른데... '}] 10\n"
     ]
    }
   ],
   "source": [
    "# 네이버 검색 API 예제 - 지식in 검색\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('Client_ID')\n",
    "client_secret = os.getenv('Client_Secret')\n",
    "\n",
    "encText = urllib.parse.quote(\"쳇지피티\")\n",
    "\n",
    "url = \"https://openapi.naver.com/v1/search/kin.json?query=\" + encText  # JSON 결과\n",
    "# url = \"https://openapi.naver.com/v1/search/kin.xml?query=\" + encText # XML 결과\n",
    "\n",
    "headers = {\n",
    "    \"X-Naver-Client-Id\": client_id,\n",
    "    \"X-Naver-Client-Secret\": client_secret\n",
    "}\n",
    "request = urllib.request.Request(url, headers=headers)\n",
    "\n",
    "# request = urllib.request.Request(url)\n",
    "# request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "# request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "\n",
    "if (rescode == 200):\n",
    "    response_body = response.read()\n",
    "    # print(type(response_body.decode('utf-8')))\n",
    "\n",
    "    data = json.loads(response_body.decode('utf-8'))  # json 형태의 str을 딕셔너리\n",
    "    # print(type(data), data)\n",
    "    print(data['items'], len(data['items']))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a01584c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>제21대 대통령 선거 사전투표 모바일 신분증</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 3.(화) 06:00~20:00 ○ 투표장소 : 주민등록지 내 지정된 투표소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21대 대통령선거 사전투표</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 안녕하세요 2025년 제21대 대통령선거 사전투표 관련해서 질문 주셨네요. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21대 대통령선거 사전투표</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>21대 대통령 선거 투표 29일날 할려고 하는데요 사전투표는 아무대나 가서해도 상관...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21대 대통령선거 사전투표</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... ✔️ 사전투표 (선거 전 이틀간) → **전국 어디서나** 가까운 사전투표소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이번 대통령 선거 사전투표 날짜</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>제가 대선날 일정이 있어서 투표하기 어려운데, 이번 대통령 선거 사전투표 날짜가 언...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21대 연천 대통령선거 사전투표 위치가 어디에요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>제 21대 연천 대통령선거 사전투표 위치가 어디에요? 본 투표때 일정이 안될것같아서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>선거 사전투표소 질문있습니다</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 사전투표 vs 선거일(본투표) 투표소 이용 방식에 대해 헷갈리기 쉬운 포인트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>부산시 교육감 재보궐선거 사전투표</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>오늘 부산에서 하고있는 교육감 재보궐선거 사전투표에 대한 질문드립니다. 제가 고향이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>지방선거 사전투표 타지역</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 혹시 지방선거 사전투표 타지역에서 할 수 있나요? 6.1 지방선거 타지역 구...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21대 대통령선거 사전투표 하려고하는데 다른지역</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>21대 대통령선거 사전투표 하려고하는데 다른지역 가서 해도 되나요?? 사전투표는 꼭...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>이번 대통령 선거에 사전투표를 평일에 하나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 아는데요 이번 대선 사전투표는 이틀 모두 평일이 된거 이상하네요 6/3일이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>부산교육감 보궐선거 사전투표를 서울에서 할 수 있나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>부산교육감 보궐선거 사전투표를 서울의 보궐선거 실시 지역에서 할 수 있나요? 부산교...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10월 16일 재보궐선거 사전투표소</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>10월 16일 재보궐선거할때 사전투표소어디에요? 10월 16일 재보궐선거 사전투표소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>사전선거운동과 관련된 선거법위반</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 대선전 사전선거운동에 해당되는지요? 감사합니다. 현직 국회의원이, 대선3년전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>사전투표 부정선거</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>2020 총선 사전투표에서 유독 가짜투표용지 나와서 부정선거 논란이었는데 최근 총선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>선거사무원 알바생도 사전투표날에 투표가능한가요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 선거알바를 하게 되었는데 사전투표날에 하게되었습니다. 알바하면서 쉬는시간 생...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>선거벽보에 사전투표장소 안내 벽보도 해당되나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 아파트 등 공공장소에 부착된 사전투표소 안내 벽보도 공직선거법의 보호를 받는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>더블어민주당 부정선거 의혹</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 총선 사전선거 투표함에서 신권다발과 같은 빳빳한 투표지가 나온 바, 소송에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>사전선거운동 위반</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>후보등록을 하기전에 홍보물을 우편으로 유권자에게 보내도 되나요? ,1 후보 등록 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>사전선거 인명부는 죽어도 못 내놔</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>당일 선거 인명부는 재검표할 때 선관위가 내놓습니다 사전선거는 인명부를 내놓으라고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>대통령 선거 사전 투표 질문</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 중앙선거관리위원회 홈페이지나 포털에서 “사전투표소 찾기” 검색하시면 가장 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>만약에 검찰총장 시절 검찰 특활비로 사전 선거운동하면...</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>만약에 검찰총장 시절 검찰 특활비로 사전 선거운동하면 탄핵 사유 가 될 수 있습니다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>사전선거 관련</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 이번 21대 국회의원 선거가 4월10일, 11일(사전선거), 4월15일(본선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>오늘 사전선거일 전화선거운동 가능한가요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>오늘이 사전선거 당일인데요 전화로 선거운동 하는거 가능한가요? [사회 정의를 바라는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>대통령선거 사전투표하면</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 제 주소지는 충남이며 부모님은 대전에 사시고 사전 투표를 대전에서 하려고 합...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>전국지방선거 사전투표</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>전국지방선거 사전투표를 하는 경우 본인 살고 있는 동에 행정복지센터가 아닌 다른 동...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>사전선거 제도</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>한국에서 이렇게 문제 많은 사전선거를 처음 누가 주도해서 만든건가요? 사전투표를 의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>사전 선거 장소</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 근데 지금은 부산 살고 있는데 사전 선거는 부산에서 해도 되나요?? 9일 선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>사전선거 카톡지갑으로 신분 증명 방법</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>사전선거에서 모바일 신분증을 사용할 수 있고, 그중에 카톡 지갑도 사용 가능하다고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>아파트 동대표 사전선거운동관련</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 아파트 동별 대표자 선출선거에 있어서 입후보 등록을 하지 아니한 자가 부녀회...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0            제21대 대통령 선거 사전투표 모바일 신분증   \n",
       "1                      21대 대통령선거 사전투표   \n",
       "2                      21대 대통령선거 사전투표   \n",
       "3                      21대 대통령선거 사전투표   \n",
       "4                   이번 대통령 선거 사전투표 날짜   \n",
       "5         21대 연천 대통령선거 사전투표 위치가 어디에요?   \n",
       "6                     선거 사전투표소 질문있습니다   \n",
       "7                  부산시 교육감 재보궐선거 사전투표   \n",
       "8                       지방선거 사전투표 타지역   \n",
       "9          21대 대통령선거 사전투표 하려고하는데 다른지역   \n",
       "10          이번 대통령 선거에 사전투표를 평일에 하나요?   \n",
       "11     부산교육감 보궐선거 사전투표를 서울에서 할 수 있나요?   \n",
       "12                10월 16일 재보궐선거 사전투표소   \n",
       "13                  사전선거운동과 관련된 선거법위반   \n",
       "14                          사전투표 부정선거   \n",
       "15         선거사무원 알바생도 사전투표날에 투표가능한가요?   \n",
       "16         선거벽보에 사전투표장소 안내 벽보도 해당되나요?   \n",
       "17                     더블어민주당 부정선거 의혹   \n",
       "18                          사전선거운동 위반   \n",
       "19                 사전선거 인명부는 죽어도 못 내놔   \n",
       "20                    대통령 선거 사전 투표 질문   \n",
       "21  만약에 검찰총장 시절 검찰 특활비로 사전 선거운동하면...    \n",
       "22                            사전선거 관련   \n",
       "23             오늘 사전선거일 전화선거운동 가능한가요?   \n",
       "24                       대통령선거 사전투표하면   \n",
       "25                        전국지방선거 사전투표   \n",
       "26                            사전선거 제도   \n",
       "27                           사전 선거 장소   \n",
       "28               사전선거 카톡지갑으로 신분 증명 방법   \n",
       "29                   아파트 동대표 사전선거운동관련   \n",
       "\n",
       "                                                 link  \\\n",
       "0   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "1   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "2   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "3   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "4   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "5   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "6   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "7   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "8   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "9   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "10  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "11  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "12  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "13  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "14  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "15  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "16  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "17  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "18  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "19  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "20  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "21  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "22  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "23  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "24  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "25  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "26  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "27  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "28  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "29  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "\n",
       "                                          description  \n",
       "0   ... 3.(화) 06:00~20:00 ○ 투표장소 : 주민등록지 내 지정된 투표소...  \n",
       "1   ... 안녕하세요 2025년 제21대 대통령선거 사전투표 관련해서 질문 주셨네요. ...  \n",
       "2   21대 대통령 선거 투표 29일날 할려고 하는데요 사전투표는 아무대나 가서해도 상관...  \n",
       "3   ... ✔️ 사전투표 (선거 전 이틀간) → **전국 어디서나** 가까운 사전투표소...  \n",
       "4   제가 대선날 일정이 있어서 투표하기 어려운데, 이번 대통령 선거 사전투표 날짜가 언...  \n",
       "5   제 21대 연천 대통령선거 사전투표 위치가 어디에요? 본 투표때 일정이 안될것같아서...  \n",
       "6   ... 사전투표 vs 선거일(본투표) 투표소 이용 방식에 대해 헷갈리기 쉬운 포인트...  \n",
       "7   오늘 부산에서 하고있는 교육감 재보궐선거 사전투표에 대한 질문드립니다. 제가 고향이...  \n",
       "8   ... 혹시 지방선거 사전투표 타지역에서 할 수 있나요? 6.1 지방선거 타지역 구...  \n",
       "9   21대 대통령선거 사전투표 하려고하는데 다른지역 가서 해도 되나요?? 사전투표는 꼭...  \n",
       "10  ... 아는데요 이번 대선 사전투표는 이틀 모두 평일이 된거 이상하네요 6/3일이 ...  \n",
       "11  부산교육감 보궐선거 사전투표를 서울의 보궐선거 실시 지역에서 할 수 있나요? 부산교...  \n",
       "12  10월 16일 재보궐선거할때 사전투표소어디에요? 10월 16일 재보궐선거 사전투표소...  \n",
       "13  ... 대선전 사전선거운동에 해당되는지요? 감사합니다. 현직 국회의원이, 대선3년전...  \n",
       "14  2020 총선 사전투표에서 유독 가짜투표용지 나와서 부정선거 논란이었는데 최근 총선...  \n",
       "15  ... 선거알바를 하게 되었는데 사전투표날에 하게되었습니다. 알바하면서 쉬는시간 생...  \n",
       "16  ... 아파트 등 공공장소에 부착된 사전투표소 안내 벽보도 공직선거법의 보호를 받는...  \n",
       "17  ... 총선 사전선거 투표함에서 신권다발과 같은 빳빳한 투표지가 나온 바, 소송에서...  \n",
       "18  후보등록을 하기전에 홍보물을 우편으로 유권자에게 보내도 되나요? ,1 후보 등록 마...  \n",
       "19  당일 선거 인명부는 재검표할 때 선관위가 내놓습니다 사전선거는 인명부를 내놓으라고 ...  \n",
       "20  ... 중앙선거관리위원회 홈페이지나 포털에서 “사전투표소 찾기” 검색하시면 가장 가...  \n",
       "21  만약에 검찰총장 시절 검찰 특활비로 사전 선거운동하면 탄핵 사유 가 될 수 있습니다...  \n",
       "22  ... 이번 21대 국회의원 선거가 4월10일, 11일(사전선거), 4월15일(본선...  \n",
       "23  오늘이 사전선거 당일인데요 전화로 선거운동 하는거 가능한가요? [사회 정의를 바라는...  \n",
       "24  ... 제 주소지는 충남이며 부모님은 대전에 사시고 사전 투표를 대전에서 하려고 합...  \n",
       "25  전국지방선거 사전투표를 하는 경우 본인 살고 있는 동에 행정복지센터가 아닌 다른 동...  \n",
       "26  한국에서 이렇게 문제 많은 사전선거를 처음 누가 주도해서 만든건가요? 사전투표를 의...  \n",
       "27  ... 근데 지금은 부산 살고 있는데 사전 선거는 부산에서 해도 되나요?? 9일 선...  \n",
       "28  사전선거에서 모바일 신분증을 사용할 수 있고, 그중에 카톡 지갑도 사용 가능하다고 ...  \n",
       "29  ... 아파트 동별 대표자 선출선거에 있어서 입후보 등록을 하지 아니한 자가 부녀회...  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네이버 검색 API 예제 - 지식in 검색\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('Client_ID')\n",
    "client_secret = os.getenv('Client_Secret')\n",
    "\n",
    "keyword = \"사전선거\"\n",
    "cnt = 30\n",
    "\n",
    "url = f\"https://openapi.naver.com/v1/search/kin.json?query={keyword}&display={cnt}\"  # JSON 결과\n",
    "# url = f\"https://openapi.naver.com/v1/search/kin.xml?query={keyword}\" # XML 결과\n",
    "\n",
    "headers = {\n",
    "    \"X-Naver-Client-Id\": client_id,\n",
    "    \"X-Naver-Client-Secret\": client_secret\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "# response.status_code\n",
    "rescode = response.status_code\n",
    "\n",
    "if (rescode == 200):\n",
    "    # response_body = response.text\n",
    "    # data = json.loads(response_body)['items']\n",
    "    # print(data)\n",
    "\n",
    "    # items = json.loads(response_body)['items'] 은 방법2오 방법1 모두 쓸수 있지만\n",
    "    items = response.json()['items']  # 방법1에서만 쓸수 있는 .json()\n",
    "\n",
    "    items_list = []\n",
    "\n",
    "    for item in items:\n",
    "        items_list.append([\n",
    "            item.get('title').replace(\"<b>\", \"\").replace('</b>', ''),\n",
    "            item.get('link'),\n",
    "            item.get('description').replace(\"<b>\", \"\").replace('</b>', '')\n",
    "        ])\n",
    "\n",
    "    # print(items_list[:2])\n",
    "\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "\n",
    "df = pd.DataFrame(items_list, columns=['title', 'link', 'description'])\n",
    "df\n",
    "# print(df.loc[0,'link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b3eee4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일본지진 동일본</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>일본이 지진이 잘 자주 나는 나라라고 아는데 유튜브 보니까 대부분 지진이 동일본쪽에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일본 여행 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>9월말에 오사카 여행이 계획되어있는데 지금 일본 지진이 오사카 난바에 영향을 주나요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일본에서 지진났다는 뉴스 본 꿈</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 일본지진 7.5 로 뉴스 속보를 보는중에 깨어났습니다. 하루종일 마음이 안좋...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일본 지진 경제</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=11...</td>\n",
       "      <td>... 어떻게 보면, 지진이라는 게 일본에는 흔하게 일어나다보니 오히려 역으로 생각...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일본은 왜 지진이 자주 일어나는건가요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>일본 지진이야기를 많이난다는 이야기를 듣다가 생긴 궁금점이네요 판구조론이란 지구는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>일본지진 한국지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>... 일본의 지속적인 지진 경험으로 인해 그러한 인식이 자리잡혔습니다. 결론적으로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>일본 지진 여파</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=11...</td>\n",
       "      <td>... 그리고 일본 경제 붕괴로 인해 생길 우리나라의 피해도 구체적으로 적어주세요 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>일본 지진 상황을 알 수 있는 한국 사이트가 있나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>일본 지진 상황에 대해 아래 내용이 궁금해요. 1. 일본 지진 상황을 알 수 있는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>일본 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>... 안전하다는 건 아니고,일본 전체가 지진 위험에서 자유롭진 않아요.유튜브에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>한국 일본 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>한국은 지진 3.0이정도만 나도 난리나는데 일본은 지진 3.0이정도는 그냥 넘어가나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025년 7월 5일에 일본에서 지진이 일어난다는데 맞</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>2025년 7월 5일에 일본에서 지진이 일어난다는데 맞나요 예언이 있더라구요 안녕하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>일본 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "      <td>우리나라는 지진 3.0,2.0 조금만 지진일어나면 난리나는데 옆나라인 일본은 그렇지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>일본 지진;</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>... 알 수가 없습니다. 지진의 발생을 정확히 예측 할 수 있다면 현재 일본에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>일본의 화산으로 인한 지진이 한국에도 영향이 오나요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=11...</td>\n",
       "      <td>... 따라서 지인하고 이야기 하는 내용과 관련해서는 우리나라가 간접 피해를 입을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>일본 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>... 물론 7.1로 큰 규모이긴 하지만 그정도 지진은 일본에선 거의 매년 일어나는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>일본 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>... 일본에 지진이 많이 일어나는 건 알고 있었고, 그걸 각오하고도 가고 싶은 맘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>일본 지진 날까요?</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>... 노벨상감 아닌가요 누구도 정확히 예측하지 못하는게 자연재해입니다 일본은 지진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>일본 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>2월 말쯤에 일본여행을 가는데요 지진이 날 확률이 많은가요? 괜찮겠죠..? 자연재해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>일본 지진 (후쿠오카 영향)</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=9&amp;...</td>\n",
       "      <td>6월 초에 일본 후쿠오카에 갈 예정인데 지진피해 있을까요? 안녕하세요? 천제지변은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>일본 지진</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=6&amp;...</td>\n",
       "      <td>지금 대지진 예보 뜨고 일본이 지진으로 엄청 난리잖아요 왜 그런거조?.? 원래 지진...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "0                         일본지진 동일본   \n",
       "1                         일본 여행 지진   \n",
       "2                일본에서 지진났다는 뉴스 본 꿈   \n",
       "3                         일본 지진 경제   \n",
       "4            일본은 왜 지진이 자주 일어나는건가요?   \n",
       "5                        일본지진 한국지진   \n",
       "6                         일본 지진 여파   \n",
       "7    일본 지진 상황을 알 수 있는 한국 사이트가 있나요?   \n",
       "8                            일본 지진   \n",
       "9                         한국 일본 지진   \n",
       "10  2025년 7월 5일에 일본에서 지진이 일어난다는데 맞   \n",
       "11                           일본 지진   \n",
       "12                          일본 지진;   \n",
       "13   일본의 화산으로 인한 지진이 한국에도 영향이 오나요?   \n",
       "14                           일본 지진   \n",
       "15                           일본 지진   \n",
       "16                      일본 지진 날까요?   \n",
       "17                           일본 지진   \n",
       "18                 일본 지진 (후쿠오카 영향)   \n",
       "19                           일본 지진   \n",
       "\n",
       "                                                 link  \\\n",
       "0   https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "1   https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "2   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "3   https://kin.naver.com/qna/detail.naver?d1id=11...   \n",
       "4   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "5   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "6   https://kin.naver.com/qna/detail.naver?d1id=11...   \n",
       "7   https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "8   https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "9   https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "10  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "11  https://kin.naver.com/qna/detail.naver?d1id=8&...   \n",
       "12  https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "13  https://kin.naver.com/qna/detail.naver?d1id=11...   \n",
       "14  https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "15  https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "16  https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "17  https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "18  https://kin.naver.com/qna/detail.naver?d1id=9&...   \n",
       "19  https://kin.naver.com/qna/detail.naver?d1id=6&...   \n",
       "\n",
       "                                          description  \n",
       "0   일본이 지진이 잘 자주 나는 나라라고 아는데 유튜브 보니까 대부분 지진이 동일본쪽에...  \n",
       "1   9월말에 오사카 여행이 계획되어있는데 지금 일본 지진이 오사카 난바에 영향을 주나요...  \n",
       "2   ... 일본지진 7.5 로 뉴스 속보를 보는중에 깨어났습니다. 하루종일 마음이 안좋...  \n",
       "3   ... 어떻게 보면, 지진이라는 게 일본에는 흔하게 일어나다보니 오히려 역으로 생각...  \n",
       "4   일본 지진이야기를 많이난다는 이야기를 듣다가 생긴 궁금점이네요 판구조론이란 지구는 ...  \n",
       "5   ... 일본의 지속적인 지진 경험으로 인해 그러한 인식이 자리잡혔습니다. 결론적으로...  \n",
       "6   ... 그리고 일본 경제 붕괴로 인해 생길 우리나라의 피해도 구체적으로 적어주세요 ...  \n",
       "7   일본 지진 상황에 대해 아래 내용이 궁금해요. 1. 일본 지진 상황을 알 수 있는 ...  \n",
       "8   ... 안전하다는 건 아니고,일본 전체가 지진 위험에서 자유롭진 않아요.유튜브에서 ...  \n",
       "9   한국은 지진 3.0이정도만 나도 난리나는데 일본은 지진 3.0이정도는 그냥 넘어가나...  \n",
       "10  2025년 7월 5일에 일본에서 지진이 일어난다는데 맞나요 예언이 있더라구요 안녕하...  \n",
       "11  우리나라는 지진 3.0,2.0 조금만 지진일어나면 난리나는데 옆나라인 일본은 그렇지...  \n",
       "12  ... 알 수가 없습니다. 지진의 발생을 정확히 예측 할 수 있다면 현재 일본에서 ...  \n",
       "13  ... 따라서 지인하고 이야기 하는 내용과 관련해서는 우리나라가 간접 피해를 입을 ...  \n",
       "14  ... 물론 7.1로 큰 규모이긴 하지만 그정도 지진은 일본에선 거의 매년 일어나는...  \n",
       "15  ... 일본에 지진이 많이 일어나는 건 알고 있었고, 그걸 각오하고도 가고 싶은 맘...  \n",
       "16  ... 노벨상감 아닌가요 누구도 정확히 예측하지 못하는게 자연재해입니다 일본은 지진...  \n",
       "17  2월 말쯤에 일본여행을 가는데요 지진이 날 확률이 많은가요? 괜찮겠죠..? 자연재해...  \n",
       "18  6월 초에 일본 후쿠오카에 갈 예정인데 지진피해 있을까요? 안녕하세요? 천제지변은 ...  \n",
       "19  지금 대지진 예보 뜨고 일본이 지진으로 엄청 난리잖아요 왜 그런거조?.? 원래 지진...  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수 작성\n",
    "# 네이버 검색 API 예제 - 지식in 검색\n",
    "def get_naver_kin(keyword, cnt=10):\n",
    "    import os\n",
    "    import sys\n",
    "    import requests\n",
    "    import json\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    client_id = os.getenv('Client_ID')\n",
    "    client_secret = os.getenv('Client_Secret')\n",
    "\n",
    "    url = f\"https://openapi.naver.com/v1/search/kin.json?query={keyword}&display={cnt}\"  # JSON 결과\n",
    "    # url = f\"https://openapi.naver.com/v1/search/kin.xml?query={keyword}\" # XML 결과\n",
    "\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": client_id,\n",
    "        \"X-Naver-Client-Secret\": client_secret\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    rescode = response.status_code\n",
    "\n",
    "    if (rescode == 200):\n",
    "        # response_body = response.text\n",
    "        # data = json.loads(response_body)['items']\n",
    "        # print(data)\n",
    "\n",
    "        # items = json.loads(response_body)['items'] 은 방법2오 방법1 모두 쓸수 있지만\n",
    "        items = response.json()['items']  # 방법1에서만 쓸수 있는 .json()\n",
    "\n",
    "        items_list = []\n",
    "\n",
    "        for item in items:\n",
    "            items_list.append([\n",
    "                item.get('title').replace(\"<b>\", \"\").replace('</b>', ''),\n",
    "                item.get('link'),\n",
    "                item.get('description').replace(\"<b>\", \"\").replace('</b>', '')\n",
    "            ])\n",
    "\n",
    "        # print(items_list[:2])\n",
    "\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "\n",
    "    df = pd.DataFrame(items_list, columns=['title', 'link', 'description'])\n",
    "    df.to_csv(f'./data/ch14_{keyword}.csv', index=False)\n",
    "    return df\n",
    "    # print(df.loc[0,'link'])\n",
    "\n",
    "\n",
    "get_naver_kin('일본지진', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddae0a",
   "metadata": {},
   "source": [
    "### quiz) 네이버 open API를 이용해서 청바지 이미지 100건 데이터를"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "dff2d8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openapi.naver.com/v1/search/image?query=%EC%B2%AD%EB%B0%94%EC%A7%80&display=100\n"
     ]
    }
   ],
   "source": [
    "# quiz) 네이버 open API를 이용해서 청바지 이미지 100건 데이터를¶\n",
    "# 데이터 : 제목, 이미지링크, 썸네일링크, 넓이, 폭\n",
    "import urllib.parse\n",
    "\n",
    "word = '청바지'\n",
    "word = urllib.parse.quote(word)\n",
    "url = f\"https://openapi.naver.com/v1/search/image?query={word}&display=100\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "41d30066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>sizeheight</th>\n",
       "      <th>sizewidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BINIWU 심플 빈티지 워싱 청바지 남자 봄가을 루즈핏 통바지 28 빈티지블루</td>\n",
       "      <td>http://shopping.phinf.naver.net/main_5172227/5...</td>\n",
       "      <td>https://search.pstatic.net/common/?type=b150&amp;s...</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                         title  \\\n",
       "0   1  BINIWU 심플 빈티지 워싱 청바지 남자 봄가을 루즈핏 통바지 28 빈티지블루   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://shopping.phinf.naver.net/main_5172227/5...   \n",
       "\n",
       "                                           thumbnail sizeheight sizewidth  \n",
       "0  https://search.pstatic.net/common/?type=b150&s...        800       800  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('Client_ID')\n",
    "client_secret = os.getenv('Client_Secret')\n",
    "\n",
    "word = '청바지'\n",
    "cnt = 100\n",
    "\n",
    "url = f\"https://openapi.naver.com/v1/search/image?query={word}&display={cnt}\"  # JSON 결과\n",
    "# url = f\"https://openapi.naver.com/v1/search/image.xml\t?query={word}\" # XML 결과\n",
    "\n",
    "headers = {\n",
    "    \"X-Naver-Client-Id\": client_id,\n",
    "    \"X-Naver-Client-Secret\": client_secret\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "rescode = response.status_code\n",
    "\n",
    "if (rescode == 200):\n",
    "    # response_body = response.text\n",
    "    # data = json.loads(response_body)['items']\n",
    "    # print(data)\n",
    "\n",
    "    # items = json.loads(response_body)['items'] 은 방법2오 방법1 모두 쓸수 있지만\n",
    "    items = response.json()['items']  # 방법1에서만 쓸수 있는 .json()\n",
    "    # print(items[0])\n",
    "    items_list = []\n",
    "\n",
    "    for idx, item in enumerate(items):\n",
    "        #         items_list.append([\n",
    "        #             item.get('title'),\n",
    "        #             item.get('link'),\n",
    "        #             item.get('thumbnail'),\n",
    "        #             item.get('sizeheight'),\n",
    "        #             item.get('sizewidth')\n",
    "        #         ])\n",
    "        title = item.get('title')\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        sizeheight = item.get('sizeheight')\n",
    "        sizewidth = item.get('sizewidth')\n",
    "\n",
    "        items_list.append({\n",
    "            'no': idx + 1,\n",
    "            'title': title,\n",
    "            'link': link,\n",
    "            'thumbnail': thumbnail,\n",
    "            'sizeheight': sizeheight,\n",
    "            \"sizewidth\": sizewidth\n",
    "        })\n",
    "        # link와 thumbnail을 저장\n",
    "\n",
    "    #print(items_list[:2])\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "\n",
    "df = pd.DataFrame(items_list)\n",
    "df.head(1)\n",
    "# df\n",
    "# df.to_csv(f'./data/ch14_{word}_{size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "91895d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://shop1.phinf.naver.net/20250503_295/1746250611381Vinxl_JPEG/21192829047529977_2039968073.jpeg'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5, 'link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f0e71ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>sizeheight</th>\n",
       "      <th>sizewidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [no, title, link, thumbnail, sizeheight, sizewidth]\n",
       "Index: []"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['link'].str.find('?')!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "717b3305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://shop1.phinf.naver.net/20250503_295/1746250611381Vinxl_JPEG/21192829047529977_2039968073.jpeg'"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['link'].str.endswith('jpg')].loc[5, 'link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7e7f5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(attr, idx, query, url):\n",
    "    '{attr}_{idx}_{query}.{확장자} 이미지 저장'\n",
    "    \n",
    "    # 확장자 뽑는 법\n",
    "    file_extension = url.split('.')[-1]\n",
    "    # print(file_extension)\n",
    "    \n",
    "    # ?가 있을 경우\n",
    "    quote_index = file_extension.find('?')\n",
    "    # print(quote_index)\n",
    "    if quote_index != -1:\n",
    "        file_extension = file_extension[:quote_index]\n",
    "    # if len(file_extension) > 10:\n",
    "        # file_extension = 'jpg'\n",
    "    \n",
    "    \n",
    "    # print(file_extension)\n",
    "    \n",
    "    img = requests.get(url).content\n",
    "    \n",
    "    # 파일 열기\n",
    "    # with open(f'./ch14_image/{arrt}_{idx}_{query}.{file_extension}', 'wb') as f:\n",
    "    #  f.write(img)\n",
    "    open(f'./ch14_image/{attr}_{idx}_{query}.{file_extension}', 'wb').write(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "7effcc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img('메인', 1, '청바지', df.loc[5, 'link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "22d132b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word image 100개 검색한 데이터는 csv파일로, 이미지는 ch14_image폴더에 저장되는 함수\n",
    "# quiz) 네이버 open API를 이용해서 청바지 이미지 100건 데이터를\n",
    "# 데이터 : 제목, 이미지링크, 썸네일링크, 넓이, 폭\n",
    "def get_naver_save_image(word):\n",
    "    import os\n",
    "    import sys\n",
    "    import requests\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    client_id = os.getenv('Client_ID')\n",
    "    client_secret = os.getenv('Client_Secret')\n",
    "\n",
    "    cnt = 100\n",
    "\n",
    "    url = f\"https://openapi.naver.com/v1/search/image?query={word}&display={cnt}\"  # JSON 결과\n",
    "    # url = f\"https://openapi.naver.com/v1/search/image.xml\t?query={word}\" # XML 결과\n",
    "\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": client_id,\n",
    "        \"X-Naver-Client-Secret\": client_secret\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    rescode = response.status_code\n",
    "\n",
    "    if (rescode == 200):\n",
    "        # response_body = response.text\n",
    "        # data = json.loads(response_body)['items']\n",
    "        # print(data)\n",
    "\n",
    "        # items = json.loads(response_body)['items'] 은 방법2오 방법1 모두 쓸수 있지만\n",
    "        items = response.json()['items']  # 방법1에서만 쓸수 있는 .json()\n",
    "        # print(items[0])\n",
    "        items_list = []\n",
    "\n",
    "        for idx, item in enumerate(items):\n",
    "            title = item.get('title')\n",
    "            link = item.get('link')\n",
    "            thumbnail = item.get('thumbnail')\n",
    "            sizeheight = item.get('sizeheight')\n",
    "            sizewidth = item.get('sizewidth')\n",
    "\n",
    "            items_list.append({\n",
    "                'no': idx + 1,\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'thumbnail': thumbnail,\n",
    "                'sizeheight': sizeheight,\n",
    "                \"sizewidth\": sizewidth\n",
    "            })\n",
    "            # link와 thumbnail을 저장\n",
    "\n",
    "            #print(items_list[:2])\n",
    "            save_img('메인', idx + 1, word, link)\n",
    "            save_img('썸네일', idx + 1, word, thumbnail)\n",
    "\n",
    "            # 20%, 40%, 60%, 80% 지점에 message 출력\n",
    "            if idx / 20 == round(idx / 20):\n",
    "                print(f'🤚🤚🤚 {idx+1}% 진행 중입니다.')\n",
    "            # print(f'=*{idx}',end='')\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(items_list)\n",
    "    df.to_csv(f'./ch14_image/{word}.csv', index=False)\n",
    "    print('✅',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4e75f262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤚🤚🤚 1% 진행 중입니다.\n",
      "🤚🤚🤚 21% 진행 중입니다.\n",
      "🤚🤚🤚 41% 진행 중입니다.\n",
      "🤚🤚🤚 61% 진행 중입니다.\n",
      "🤚🤚🤚 81% 진행 중입니다.\n",
      "✅"
     ]
    }
   ],
   "source": [
    "get_naver_save_image('청바지')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f9a53",
   "metadata": {},
   "source": [
    "## 2.3. xml. 파일\n",
    "- 기상예측 RSS 활용\n",
    "- https://www.kma.go.kr/repositary/xml/fct/mon/img/fct_mon1rss_108_20250529.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "168bd725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지역</th>\n",
       "      <th>1주평년기온</th>\n",
       "      <th>1주범위</th>\n",
       "      <th>1주최저</th>\n",
       "      <th>1주최고</th>\n",
       "      <th>2주평년기온</th>\n",
       "      <th>2주범위</th>\n",
       "      <th>2주최저</th>\n",
       "      <th>2주최고</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전국(제주도,북한제외)</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.6~21.6</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.5~22.3</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울ㆍ인천ㆍ경기도</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.1~22.1</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>22.4</td>\n",
       "      <td>22.0~22.8</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강원도 영서</td>\n",
       "      <td>20.3</td>\n",
       "      <td>19.7~20.9</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.7~21.9</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>강원도 영동</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.2~20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.4~20.8</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>대전ㆍ세종ㆍ충청남도</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.0~22.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>22.3</td>\n",
       "      <td>21.9~22.7</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>충청북도</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.7~21.9</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>22.2</td>\n",
       "      <td>21.8~22.6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>광주ㆍ전라남도</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.9~21.7</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.7~22.3</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>전북자치도</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.9~21.7</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.7~22.5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>부산ㆍ울산ㆍ경상남도</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.8~21.8</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.7~22.5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>대구ㆍ경상북도</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.3~21.5</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.3~22.5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>제주도</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.6~21.4</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.2~22.0</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>평안남북도ㆍ황해도</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.0~21.2</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.0~22.0</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>함경남북도</td>\n",
       "      <td>16.6</td>\n",
       "      <td>15.9~17.3</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.1~18.3</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                지역  1주평년기온       1주범위  1주최저  1주최고  2주평년기온       2주범위  2주최저  \\\n",
       "0    전국(제주도,북한제외)     21.1  20.6~21.6    10    60    21.9  21.5~22.3    20   \n",
       "1       서울ㆍ인천ㆍ경기도     21.6  21.1~22.1    10    60    22.4  22.0~22.8    20   \n",
       "2          강원도 영서     20.3  19.7~20.9    10    60    21.3  20.7~21.9    20   \n",
       "3          강원도 영동     19.1  18.2~20.0    10    60    20.1  19.4~20.8    20   \n",
       "4      대전ㆍ세종ㆍ충청남도     21.5  21.0~22.0    10    60    22.3  21.9~22.7    20   \n",
       "5            충청북도     21.3  20.7~21.9    10    60    22.2  21.8~22.6    20   \n",
       "6         광주ㆍ전라남도     21.3  20.9~21.7    10    60    22.0  21.7~22.3    20   \n",
       "7           전북자치도     21.3  20.9~21.7    10    60    22.1  21.7~22.5    20   \n",
       "8      부산ㆍ울산ㆍ경상남도     21.3  20.8~21.8    10    60    22.1  21.7~22.5    20   \n",
       "9         대구ㆍ경상북도     20.9  20.3~21.5    10    60    21.9  21.3~22.5    20   \n",
       "10            제주도     21.0  20.6~21.4    10    60    21.6  21.2~22.0    20   \n",
       "11      평안남북도ㆍ황해도     20.6  20.0~21.2    10    60    21.5  21.0~22.0    20   \n",
       "12          함경남북도     16.6  15.9~17.3    10    60    17.7  17.1~18.3    20   \n",
       "\n",
       "    2주최고  \n",
       "0     40  \n",
       "1     30  \n",
       "2     30  \n",
       "3     30  \n",
       "4     40  \n",
       "5     40  \n",
       "6     40  \n",
       "7     40  \n",
       "8     40  \n",
       "9     40  \n",
       "10    40  \n",
       "11    30  \n",
       "12    30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   지역      13 non-null     object \n",
      " 1   1주평년기온  13 non-null     float64\n",
      " 2   1주범위    13 non-null     object \n",
      " 3   1주최저    13 non-null     int64  \n",
      " 4   1주최고    13 non-null     int64  \n",
      " 5   2주평년기온  13 non-null     float64\n",
      " 6   2주범위    13 non-null     object \n",
      " 7   2주최저    13 non-null     int64  \n",
      " 8   2주최고    13 non-null     int64  \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.kma.go.kr/repositary/xml/fct/mon/img/fct_mon1rss_108_20250529.xml'\n",
    "response = urlopen(url)\n",
    "response.getcode() # response.status\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response, 'xml') # pip install Lxml\n",
    "# soup\n",
    "locals = soup.find_all('local_ta')\n",
    "# print(len(locals))\n",
    "# print(locals[1])\n",
    "\n",
    "items_list = []\n",
    "\n",
    "for local in locals:\n",
    "    local_ta_name = local.select_one('local_ta_name').text\n",
    "    week1_normalYear = local.select_one('week1_local_ta_normalYear').text # 평년기온\n",
    "    week1_similarRange = local.select_one('week1_local_ta_similarRange').text # 기온범위\n",
    "    week1_min = local.select_one('week1_local_ta_minVal').text\n",
    "    week1_max = local.select_one('week1_local_ta_maxVal').text\n",
    "    \n",
    "    week2_normalYear = local.select_one('week2_local_ta_normalYear').text # 평년기온\n",
    "    week2_similarRange = local.select_one('week2_local_ta_similarRange').text # 기온범위\n",
    "    week2_min = local.select_one('week2_local_ta_minVal').text\n",
    "    week2_max = local.select_one('week2_local_ta_maxVal').text\n",
    "    \n",
    "    items_list.append({\n",
    "        '지역':local_ta_name,\n",
    "        '1주평년기온': float(week1_normalYear),\n",
    "        '1주범위':week1_similarRange,\n",
    "        '1주최저':int(week1_min),\n",
    "        '1주최고':int(week1_max),\n",
    "        '2주평년기온': float(week2_normalYear),\n",
    "        '2주범위':week2_similarRange,\n",
    "        '2주최저':int(week2_min),\n",
    "        '2주최고':int(week2_max),\n",
    "    })\n",
    "pf = pd.DataFrame(items_list)\n",
    "display(pf)\n",
    "pf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435ad92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f4ce3c5",
   "metadata": {},
   "source": [
    "# 3. 연습문제\n",
    "\n",
    "- yes24의 베스트셀러 정보를 제공하는 사이트에서 베스트셀러 정보를 수집해서 파일에 저장하세요.\n",
    "- 베스트셀러 정보 수집 주소 : http://www.yes24.com/24/category/bestseller\n",
    "- 데이터 : 순위, 책이름, 저자및출판사, 가격 (1 ~ 24위 / 1 ~ 48위 => 데이터프레임으로 만들고)\n",
    "- ch14_yes24.csv로 출력(ch14_yes24.txt)로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d40e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "pagesNumber = 4\n",
    "items_list = []\n",
    "for pageNumber in range(1, pagesNumber + 1):\n",
    "#     print(pageNumber)\n",
    "    url = f\"https://www.yes24.com/product/category/bestseller?categoryNumber=001&pageNumber={pageNumber}\"\n",
    "#     print(url)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    numbers = soup.select('div.img_upper > em')\n",
    "    titles = soup.select('div.item_info > div.info_row.info_name > a.gd_name')\n",
    "    autors_els = soup.select(\n",
    "        'div.item_info > div.info_row.info_pubGrp span.authPub.info_auth')\n",
    "    autors_= [autors_el.text.strip() for autors_el in autors_els]\n",
    "    publishers = soup.select(\n",
    "        'div.item_info > div.info_row.info_pubGrp span:nth-child(2)')\n",
    "    prices = soup.select('div.item_info > div.info_row.info_price > strong')\n",
    "    \n",
    "    \n",
    "    for idx, (number, title, autor, publisher, price) in enumerate(zip(numbers, titles, autors, publishers, prices)):\n",
    "        pass\n",
    "#         print([number.text, title.text, autor.text.strip(), publisher.text, price.text])\n",
    "        \n",
    "#         items_list.append({\n",
    "#             \"순위\":\n",
    "#             number.text,\n",
    "#             \"책이름\":\n",
    "#             title.text,\n",
    "#             \"저자 및 출판\":\n",
    "#             autor.text.strip() + \" | \" + publisher.text.strip(),\n",
    "#             \"가격\":\n",
    "#             price.text.replace('원', '').replace(',', '')\n",
    "#         })\n",
    "# pf = pd.DataFrame(items_list)\n",
    "# display(pf.head(48))\n",
    "\n",
    "# pf.to_csv(f'./data/ch14_yes24.csv', index=False, encoding='utf-8')\n",
    "# pf.to_csv(f'./data/ch14_yes24.txt', sep='\\t', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0dd43547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['프리드리히 니체 저 / 김지민 역', '루리 글그림', '김종원 글', '백온유, 강보라, 서장원, 성해나, 성혜령 저 외 2명\\r\\n                                        \\n정보 더 보기/감추기\\n\\n\\n\\n백온유\\n강보라\\n서장원\\n성해나\\n성혜령\\n이희주\\n현호정', '김민정 저', '이현옥, 이현주 저', '안-엘렌 클레르, 뱅상 트리부 저/구영옥 역', '동공이 약사 저', '김보영 저', '김종원 글', '정해연 저', '밀란 쿤데라 저/이재룡 역', '클레어 키건 저/홍한별 역', '실비아 맥니콜 저 / 최윤정 역', '개 글그림', '허영만 글그림', '애비게일 슈라이어 저/이수경 역', '저드슨 브루어 저/김보은 역', '세이노(SayNo) 저', '김태완 저', '깡토 저', '차정은 저', '길벗놀이학습연구소 저/김희정 그림', '캐릭온TV 원저 / 안도감 글 / 김규태 그림']\n",
      "['프리드리히 니체 저 / 김지민 역', '루리 글그림', '김종원 글', '백온유, 강보라, 서장원, 성해나, 성혜령 저 외 2명\\r\\n                                        \\n정보 더 보기/감추기\\n\\n\\n\\n백온유\\n강보라\\n서장원\\n성해나\\n성혜령\\n이희주\\n현호정', '김민정 저', '이현옥, 이현주 저', '안-엘렌 클레르, 뱅상 트리부 저/구영옥 역', '동공이 약사 저', '김보영 저', '김종원 글', '정해연 저', '밀란 쿤데라 저/이재룡 역', '클레어 키건 저/홍한별 역', '실비아 맥니콜 저 / 최윤정 역', '개 글그림', '허영만 글그림', '애비게일 슈라이어 저/이수경 역', '저드슨 브루어 저/김보은 역', '세이노(SayNo) 저', '김태완 저', '깡토 저', '차정은 저', '길벗놀이학습연구소 저/김희정 그림', '캐릭온TV 원저 / 안도감 글 / 김규태 그림']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "pagesNumber = 2\n",
    "items_list = []\n",
    "for pageNumber in range(1, pagesNumber + 1):\n",
    "    url = f\"https://www.yes24.com/product/category/bestseller?categoryNumber=001&pageNumber={pageNumber}&pageSize=24\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    numbers = soup.select('div.img_upper > em')\n",
    "    titles = soup.select('div.item_info > div.info_row.info_name > a.gd_name')\n",
    "    \n",
    "    autors_span = soup.select(\n",
    "        'div.item_info > div.info_row.info_pubGrp span.authPub.info_auth > a')\n",
    "#     autors_span = soup.find('span', class_='authPub info_auth')\n",
    "#     print(autors_span)\n",
    "    # 2) 해당 span 안의 모든 <a> 태그 추출\n",
    "#     author_links = autors_span.find_all('a')\n",
    "\n",
    "    autors= [autor.text.strip() for autor in autors_span]\n",
    "    \n",
    "    \n",
    "    print(autors_)\n",
    "    publishers = soup.select(\n",
    "        'div.item_info > div.info_row.info_pubGrp span:nth-child(2)')\n",
    "    prices = soup.select('div.item_info > div.info_row.info_price > strong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0abb50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def yes24_bestseller(pagesNumber):\n",
    "\n",
    "    items_list = []\n",
    "    for pageNumber in range(1, pagesNumber + 1):\n",
    "        url = f\"https://www.yes24.com/product/category/bestseller?categoryNumber=001&pageNumber={pageNumber}&pageSize=24\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        numbers = soup.select('div.img_upper > em')\n",
    "        titles = soup.select('div.item_info > div.info_row.info_name > a.gd_name')\n",
    "        autors = soup.select(\n",
    "            'div.item_info > div.info_row.info_pubGrp span.authPub.info_auth')\n",
    "        publishers = soup.select(\n",
    "            'div.item_info > div.info_row.info_pubGrp span:nth-child(2)')\n",
    "        prices = soup.select('div.item_info > div.info_row.info_price > strong')\n",
    "        for idx, (number, title, autor, publisher, price) in enumerate(\n",
    "                zip(numbers, titles, autors, publishers, prices)):\n",
    "            items_list.append({\n",
    "                \"순위\":\n",
    "                number.text,\n",
    "                \"책이름\":\n",
    "                title.text,\n",
    "                \"저자 및 출판\":\n",
    "                autor.text.strip() + \" | \" + publisher.text.strip(),\n",
    "                \"가격\":\n",
    "                price.text.replace('원', '').replace(',', '')\n",
    "            })\n",
    "    pf = pd.DataFrame(items_list)\n",
    "    pf.to_csv(f'./data/ch14_yes24.csv', index=False, encoding='utf-8')\n",
    "    pf.to_csv(f'./data/ch14_yes24.txt', sep='\\t', index=False, encoding='utf-8')\n",
    "    print('파일이 csv, txt 파일로 저장 완료')\n",
    "    \n",
    "    return pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ce2f70d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ptint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43myes24_bestseller\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 20\u001b[0m, in \u001b[0;36myes24_bestseller\u001b[0;34m(pagesNumber)\u001b[0m\n\u001b[1;32m     17\u001b[0m         titles \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.item_info > div.info_row.info_name > a.gd_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m         autors\u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.item_info > div.info_row.info_pubGrp span.authPub.info_auth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m         \u001b[43mptint\u001b[49m([autor \u001b[38;5;28;01mfor\u001b[39;00m autor \u001b[38;5;129;01min\u001b[39;00m autors])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#         autors = [autors_el.text.strip() for autors_el in autors_els]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         publishers \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.item_info > div.info_row.info_pubGrp span:nth-child(2)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ptint' is not defined"
     ]
    }
   ],
   "source": [
    "yes24_bestseller(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8d33976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선생님 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "pages = 2\n",
    "bestseller_list = []\n",
    "with open('data/ch14_yes24.txt', 'w', encoding='utf-8') as f:\n",
    "    pass\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://www.yes24.com/product/category/bestseller?pageNumber={page}'\n",
    "    response = requests.get(url)\n",
    "    # print(url)\n",
    "    # print(response.status_code)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    ranks_els = soup.select('div.img_upper > em.ico.rank')\n",
    "    ranks = [int(ranks_el.text) for ranks_el in ranks_els]\n",
    "    titles_els=soup.select(\"div.item_info > div.info_row > a.gd_name\")\n",
    "    titles = [titles_el.text for titles_el in titles_els]\n",
    "    writers_els = soup.select(\"span.authPub.info_auth\")\n",
    "    # writers_els = soup.find_all('span', class_='info_auth')\n",
    "    writers = [writers_el.text.strip() for writers_el in writers_els]\n",
    "    publishers_els = soup.select('div.info_row.info_pubGrp > span.authPub.info_pub')\n",
    "    publishers = [publishers_el.text for publishers_el in publishers_els]\n",
    "    prices_els = soup.select(\"div.info_row > strong.txt_num\")\n",
    "    prices = [prices_el.text for prices_el in prices_els]\n",
    "    # print(len(ranks), len(titles), len(writers), len(publishers), len(prices))\n",
    "    with open('data/ch14_yes24.txt', 'a', encoding='utf-8') as f:\n",
    "        for rank, title, writer, publisher, price in zip(ranks, titles, writers, publishers, prices):\n",
    "            # print(\"{},{},{},{},{}\".format(rank, title, writer, publisher, price))\n",
    "            f.write(f'{rank}, {title}, {writer}, {publisher}, {price}\\n')\n",
    "            bestseller_list.append([rank, title, writer, publisher, price])\n",
    "df = pd.DataFrame(bestseller_list, \n",
    "                  columns=['rank', 'title', 'writer', 'publisher', 'price'])\n",
    "df.to_csv('data/ch14_yes24.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09ae1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "pages = 2\n",
    "bestseller_list = []\n",
    "with open('data/ch14_yes24.txt', 'w', encoding='utf-8') as f:\n",
    "    pass\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://www.yes24.com/product/category/bestseller?pageNumber={page}'\n",
    "    # print(url)\n",
    "    response = urlopen(url)\n",
    "    #print(response.status)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    ranks_els = soup.select('div.img_upper > em.ico.rank')\n",
    "    ranks = [int(ranks_el.text) for ranks_el in ranks_els]\n",
    "    titles_els=soup.select(\"div.item_info > div.info_row > a.gd_name\")\n",
    "    titles = [titles_el.text for titles_el in titles_els]\n",
    "    writers_els = soup.select(\"span.authPub.info_auth\")\n",
    "    # writers_els = soup.find_all('span', class_='info_auth')\n",
    "    writers = [writers_el.text.strip() for writers_el in writers_els]\n",
    "    publishers_els = soup.select('div.info_row.info_pubGrp > span.authPub.info_pub')\n",
    "    publishers = [publishers_el.text for publishers_el in publishers_els]\n",
    "    prices_els = soup.select(\"div.info_row > strong.txt_num\")\n",
    "    prices = [prices_el.text for prices_el in prices_els]\n",
    "    # print(len(ranks), len(titles), len(writers), len(publishers), len(prices))\n",
    "    with open('data/ch14_yes24.txt', 'a', encoding='utf-8') as f:\n",
    "        for rank, title, writer, publisher, price in zip(ranks, titles, writers, publishers, prices):\n",
    "            # print(\"{},{},{},{},{}\".format(rank, title, writer, publisher, price))\n",
    "            bestseller_list.append({\n",
    "                'rank':rank, \n",
    "                'title':title,\n",
    "                'writer':writer,\n",
    "                'publisher':publisher,\n",
    "                'price':price})\n",
    "            f.write(f'{rank}, {title}, {writer}, {publisher}, {price}\\n')\n",
    "df = pd.DataFrame(bestseller_list)\n",
    "df.to_csv('data/ch14_yes24.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
